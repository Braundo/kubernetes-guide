{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>  Welcome to the Kubernetes Guide, a quick and easy-to-digest summary of core Kubernetes concepts intended to help get you from zero to proficient! </p> <p>The initial focus of this guide is to cover topics to help you pass the Kubernetes Certified Administrator (CKA) exam. As time goes on, I will add more study content here to help prepare for other Kubernetes-related topics.</p> <p></p> <p>Feel free to pick and choose any section in any order, but you'll likely be best served by following along in the default order of the site.</p> <p></p> <p>One thing to note about text formatting in this guide: you'll notice some terms always start with a capital letter (i.e. Service, Pod, etc.). This is intentional and an attempt to adhere to standard formatting as laid out in the official Kubernetes documentation. Kubernetes API objects (like the ones just mentioned) should start with a capital letter.</p> <p></p> <p></p> <p>Legal disclaimer:  </p> <ul> <li> <p>\"Kubernetes\", \"K8s\" and the Kubernetes logo are trademarks or registered trademarks of the Linux Foundation.  </p> </li> <li> <p>Neither myself nor this site are officially associated with the Linux Foundation. </p> </li> </ul> <p></p> <p> Connect with me</p> <p> Suggest changes</p>"},{"location":"about/","title":"About the Author","text":"<p>My name is Aaron Braundmeier and I've been working in the tech industry for over a decade at companies such as Mastercard, VMware, Broadcom and CVS. I've long been a Kubernetes fan and had the privilege of working hands-on in that space during my time within the Tanzu business unit at VMware. Please note that all opinions and content on this site belong to me and do not reflect the opinions, plans, or designs of any of my current or former employers.</p> <p>I'm a Certified Kubernetes Administrator (CKA) and am always interesting in learning and being hands-on with all things Kubernetes.</p> <p>If you're interested in connecting, I can be reached in the following ways:</p> <p> aaron@braundmeier.com</p> <p> LinkedIn</p> <p> Signal</p> <p></p>"},{"location":"certification-preparation/","title":"Kubernetes Certification Preparation","text":"<p>Preparing for Kubernetes certification exams, such as the Certified Kubernetes Administrator (CKA) and Certified Kubernetes Application Developer (CKAD), requires a solid understanding of Kubernetes concepts and hands-on practice.</p>"},{"location":"certification-preparation/#exam-overview","title":"Exam Overview","text":"Certified Kubernetes Administrator (CKA) <p>The CKA exam tests your ability to perform the responsibilities of a Kubernetes administrator, including:</p> <ul> <li>Cluster Architecture, Installation &amp; Configuration: Setting up and configuring a Kubernetes cluster.</li> <li>Workloads &amp; Scheduling: Managing Pods, Deployments, and scheduling.</li> <li>Services &amp; Networking: Configuring services and networking policies.</li> <li>Storage: Managing persistent and ephemeral storage.</li> <li>Troubleshooting: Diagnosing and resolving cluster issues.</li> </ul> Certified Kubernetes Application Developer (CKAD) <p>The CKAD exam focuses on your ability to design, build, and deploy applications in Kubernetes, covering:</p> <ul> <li>Core Concepts: Understanding Pods, Deployments, and Namespaces.</li> <li>Configuration: Managing ConfigMaps and Secrets.</li> <li>Multi-Container Pods: Designing and deploying multi-container Pod patterns.</li> <li>Observability: Monitoring applications and cluster components.</li> <li>Services &amp; Networking: Configuring services, ingress, and network policies.</li> </ul>"},{"location":"certification-preparation/#study-resources","title":"Study Resources","text":"<p>The two most valuable resource types for me personally when preparing for these examinations were the books listed below and the official Kubernetes documentation. Feel free to take them or leave them; it's up to you.</p>"},{"location":"certification-preparation/#books","title":"Books","text":"Book Title Link Kubernetes Up &amp; Running Kubernetes Up &amp; Running The Kubernetes Book The Kubernetes Book Certified Kubernetes Administrator Study Guide Certified Kubernetes Administrator Study Guide Quick Start Kubernetes Quick Start Kubernetes Networking &amp; Kubernetes Networking &amp; Kubernetes Kubernetes Best Practices Kubernetes Best Practices The Book of Kubernetes The Book of Kubernetes"},{"location":"certification-preparation/#documentation","title":"Documentation","text":"Description Link Official Kubernetes documentation. Kubernetes Documentation"},{"location":"certification-preparation/#online-courses","title":"Online Courses","text":"Course Link CKA Course on Udemy CKA Course on Udemy CKAD Design &amp; Build on Pluralsight CKAD Design &amp; Build on Pluralsight"},{"location":"certification-preparation/#practice-labs","title":"Practice Labs","text":"Description Link Katacoda Katacoda Play with Kubernetes Play with Kubernetes Killer Shell killer.sh"},{"location":"certification-preparation/#exam-tips","title":"Exam Tips","text":"<ul> <li>Time Management: Practice managing your time effectively during the exam.</li> <li>Hands-On Practice: Spend ample time practicing in a real Kubernetes environment.</li> <li>Understand the Exam Format: Familiarize yourself with the exam interface and question types.</li> <li>Stay Calm: Read questions carefully and stay calm during the exam.</li> </ul>"},{"location":"configmaps-secrets/","title":"Managing Configuration and Secrets in Kubernetes","text":"<p>Modern applications require dynamic configuration management and secure handling of sensitive data. Kubernetes offers ConfigMaps and Secrets to handle these requirements efficiently, allowing you to decouple configuration from application code and manage sensitive information securely.</p>"},{"location":"configmaps-secrets/#introduction","title":"Introduction","text":"<p>In the traditional monolithic application days, environment variables and configurations were bundled up with the application and deployed as one large object. However, in the cloud-native application model it's important to decouple these for many reasons:  </p> <ol> <li>Environment Flexibility: Decoupling allows the same application to run across different environments (development, staging, production) without code changes. Environment-specific configurations can be applied externally, improving the portability of the application.</li> <li>Scalability and Dynamic Management: When configuration is externalized, it's easier to scale applications horizontally since the configuration can be managed and applied independently. This allows for dynamic reconfiguration in response to changes in load or other factors without redeploying or restarting containers.</li> <li>Security and Sensitive Data Handling: Keeping sensitive configuration data, such as secrets and credentials, separate from the application codebase helps maintain security. It ensures that sensitive data is not exposed within the code and can be securely managed using secrets management tools.</li> <li>Continuous Deployment and Rollbacks: Decoupling facilitates continuous deployment practices by allowing configurations to be updated independently of the application. This separation also simplifies rollback procedures in case a configuration change needs to be reverted without affecting the application version that's running.</li> <li>Maintainability and Clarity: Keeping configuration separate from application code helps maintain a clean codebase and makes it clearer for developers to understand the application logic. It avoids cluttering the application with environment-specific conditionals and settings, making the code easier to maintain and evolve.  </li> </ol>"},{"location":"configmaps-secrets/#understanding-configmaps","title":"Understanding ConfigMaps","text":"What are ConfigMaps? <p>ConfigMaps store non-sensitive configuration data as key-value pairs. They are first-class objects in the Kubernetes API, making them stable and widely supported.</p> Use Cases for ConfigMaps <p>ConfigMaps are ideal for storing configuration data that is not sensitive, such as:</p> <ul> <li>Environment variables</li> <li>Command-line arguments</li> <li>Configuration files</li> </ul> Creating and Using ConfigMaps <p>ConfigMaps can be created from files, directories, or literal values. Here's an example of creating a ConfigMap from a file:</p> <pre><code>kubectl create configmap my-config --from-file=config.txt\n</code></pre> <p>To use a ConfigMap in a Pod, you can reference it in the Pod's configuration:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: my-container\n    image: my-image\n    envFrom:\n    - configMapRef:\n        name: my-config\n</code></pre> Creating ConfigMaps <p>ConfigMaps can be created imperatively or declaratively.</p> Imperative Creation <p>Create a ConfigMap with literal values: <pre><code>$ kubectl create configmap app-config --from-literal=env=prod --from-literal=debug=false\n</code></pre></p> <p>Create a ConfigMap from a file: <pre><code>$ kubectl create configmap app-config --from-file=config.properties\n</code></pre></p> Declarative Creation <p>Define a ConfigMap in a YAML file (<code>configmap.yaml</code>): <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  env: prod\n  debug: \"false\"\n</code></pre></p> <p>Apply the YAML file: <pre><code>$ kubectl apply -f configmap.yaml\n</code></pre></p> Using ConfigMaps <p>Inject ConfigMap data into Pods using environment variables, command arguments, or volumes.</p> As Environment Variables <p>Define environment variables in the Pod specification: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\nspec:\n  containers:\n    - name: app-container\n      image: myapp:latest\n      env:\n        - name: ENV\n          valueFrom:\n            configMapKeyRef:\n              name: app-config\n              key: env\n        - name: DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: app-config\n              key: debug\n</code></pre></p> As Volumes <p>Mount the ConfigMap as a volume: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\nspec:\n  volumes:\n    - name: config-volume\n      configMap:\n        name: app-config\n  containers:\n    - name: app-container\n      image: myapp:latest\n      volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n</code></pre></p> Kubernetes-Native Applications <p>Kubernetes-native applications can access ConfigMap data directly via the API server, simplifying configuration management and reducing dependencies on environment variables or volumes.</p>"},{"location":"configmaps-secrets/#understanding-secrets","title":"Understanding Secrets","text":"What are Secrets? <p>Secrets store sensitive data such as passwords, tokens, and certificates. They are similar to ConfigMaps but are designed to handle sensitive information securely.</p> Are Kubernetes Secrets Secure? <p>By default, Kubernetes Secrets are not encrypted in the cluster store or in transit. They are base64-encoded, which is not secure. To enhance security, use additional tools like HashiCorp Vault for better encryption.</p> Use Cases for Secrets <p>Secrets are used to securely manage sensitive data, including:</p> <ul> <li>Database credentials</li> <li>API keys</li> <li>TLS certificates</li> </ul> Creating and Using Secrets <p>Secrets can be created imperatively or declaratively. Here's an example of creating a Secret from literal values:</p> <pre><code>kubectl create secret generic my-secret --from-literal=username=admin --from-literal=password=secret\n</code></pre> <p>To use a Secret in a Pod, you can reference it in the Pod's configuration:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: my-container\n    image: my-image\n    envFrom:\n    - secretRef:\n        name: my-secret\n</code></pre> Creating Secrets <p>Secrets can also be created imperatively or declaratively.</p> Imperative Creation <p>Create a Secret with literal values: <pre><code>$ kubectl create secret generic db-credentials --from-literal=username=dbuser --from-literal=password=securepass\n</code></pre></p> Declarative Creation <p>Define a Secret in a YAML file (<code>secret.yaml</code>): <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: db-credentials\ntype: Opaque\ndata:\n  username: ZGJ1c2Vy\n  password: c2VjdXJlcGFzcw==\n</code></pre></p> <p>Apply the YAML file: <pre><code>$ kubectl apply -f secret.yaml\n</code></pre></p> Using Secrets <p>Inject Secret data into Pods using environment variables, command arguments, or volumes.</p> As Volumes <p>Mount the Secret as a volume: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\nspec:\n  volumes:\n    - name: secret-volume\n      secret:\n        secretName: db-credentials\n  containers:\n    - name: app-container\n      image: myapp:latest\n      volumeMounts:\n        - name: secret-volume\n          mountPath: /etc/secret\n</code></pre></p>"},{"location":"configmaps-secrets/#best-practices","title":"Best Practices","text":"<ul> <li>Separate Sensitive Data: Always use Secrets for sensitive information to ensure it's not exposed in your code.</li> <li>Limit Access: Use Kubernetes RBAC to control access to ConfigMaps and Secrets.</li> <li>Encrypt Secrets: Consider using tools like HashiCorp Vault to encrypt Secrets in transit and at rest.</li> <li>Regularly Rotate Secrets: Update Secrets regularly to minimize the risk of exposure.</li> </ul>"},{"location":"configmaps-secrets/#hands-on-examples","title":"Hands-On Examples","text":"Example ConfigMap <p>Create a ConfigMap with configuration data: <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: example-config\ndata:\n  APP_ENV: \"production\"\n  APP_DEBUG: \"false\"\n</code></pre></p> <p>Deploy and inspect the ConfigMap: <pre><code>$ kubectl apply -f example-config.yaml\n$ kubectl describe configmap example-config\n</code></pre></p> Example Secret <p>Create a Secret with sensitive data: <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\ntype: Opaque\ndata:\n  username: ZGJ1c2Vy\n  password: c2VjdXJlcGFzcw==\n</code></pre></p> <p>Deploy and inspect the Secret: <pre><code>$ kubectl apply -f db-secret.yaml\n$ kubectl describe secret db-secret\n</code></pre></p>"},{"location":"configmaps-secrets/#summary","title":"Summary","text":"<p>ConfigMaps and Secrets are essential tools in Kubernetes for managing application configuration and sensitive data. By decoupling configuration from application code and handling sensitive information securely, you can create more flexible, maintainable, and secure applications.</p>"},{"location":"daemonsets/","title":"Managing DaemonSets in Kubernetes","text":"<p>DaemonSets ensure that all (or some) nodes run a copy of a Pod. They are used for deploying system-level applications like log collectors, monitoring agents, and other node-specific services.</p> Introduction to DaemonSets <p>DaemonSets are designed to manage the deployment of Pods across all nodes in a cluster. They ensure that a specific Pod is running on each node, making them ideal for system-level applications.</p> Use Cases for DaemonSets <p>DaemonSets are commonly used for:</p> <ul> <li>Log Collection: Deploying log collection agents on each node.</li> <li>Monitoring: Running monitoring agents to collect metrics from nodes.</li> <li>Networking: Managing network services like DNS or proxy servers.</li> </ul> Key Features <ul> <li>Automatic Updates: Automatically adds Pods to new nodes when they are added to the cluster.</li> <li>Selective Deployment: Can be configured to deploy Pods only to specific nodes using node selectors.</li> <li>Rolling Updates: Supports rolling updates to update Pods without downtime.</li> </ul> Managing DaemonSets <p>DaemonSets can be managed using various Kubernetes features:</p> <ul> <li>Node Selectors: Control which nodes a DaemonSet's Pods are scheduled on.</li> <li>Tolerations: Allow DaemonSet Pods to run on nodes with specific taints.</li> <li>Update Strategy: Configure rolling updates to minimize disruption.</li> </ul> Example YAML for DaemonSet <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\nspec:\n  selector:\n    matchLabels:\n      name: fluentd\n  template:\n    metadata:\n      labels:\n        name: fluentd\n    spec:\n      containers:\n      - name: fluentd\n        image: fluent/fluentd:v1.11\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: 100m\n      tolerations:\n      - key: \"node-role.kubernetes.io/master\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n</code></pre>"},{"location":"daemonsets/#best-practices","title":"Best Practices","text":"<ul> <li>Resource Management: Define resource requests and limits to ensure efficient use of node resources.</li> <li>Node Affinity: Use node affinity to control where Pods are scheduled.</li> <li>Monitor DaemonSet Health: Regularly check the status and health of DaemonSets to ensure they are running as expected.</li> <li>Scaling Considerations: Plan for scaling by understanding the resource requirements of DaemonSet Pods.</li> </ul>"},{"location":"helm-package-management/","title":"Helm","text":"<p>Helm is a powerful tool for managing Kubernetes applications. It simplifies application deployment and management by using packages called \"charts.\" This page will cover an introduction to Helm, its benefits, and how to create and use Helm charts effectively.</p>"},{"location":"helm-package-management/#introduction-to-helm","title":"Introduction to Helm","text":"What is Helm? <p>Helm is a package manager for Kubernetes that allows you to define, install, and upgrade complex Kubernetes applications. It uses a packaging format called charts, which are collections of files that describe a related set of Kubernetes resources.</p> Benefits of Using Helm <p>Helm provides several benefits for managing Kubernetes applications:</p> <ul> <li>Simplifies Deployment: Packages multiple Kubernetes resources into a single unit, making it easier to deploy complex applications.</li> <li>Versioning: Supports versioning of charts, enabling easy upgrades and rollbacks.</li> <li>Reuse: Allows you to reuse charts for different environments, reducing duplication.</li> <li>Customization: Supports customizable templates to adapt to different environments and configurations.</li> <li>Dependency Management: Manages dependencies between different charts.</li> </ul> Helm Architecture <p>Helm operates with two main components:</p> <ol> <li>Helm Client: The command-line tool that you use to create, install, and manage Helm charts.</li> <li>Helm Server (Tiller): In Helm v2, Tiller runs inside the Kubernetes cluster and manages the deployment of charts. Note that Helm v3 has removed Tiller, and the client communicates directly with the Kubernetes API server.</li> </ol> How Helm Works <ul> <li>Charts: Collections of files that describe a related set of Kubernetes resources.</li> <li>Values Files: Used to customize the deployment by overriding default values.</li> <li>Templates: Allow dynamic generation of Kubernetes manifests.</li> <li>Releases: An instance of a chart running in a Kubernetes cluster.</li> <li>Repositories: Collections of charts that can be shared and reused.</li> </ul>"},{"location":"helm-package-management/#creating-and-using-helm-charts","title":"Creating and Using Helm Charts","text":"Creating a Helm Chart <p>To create a new Helm chart, use the following command: <pre><code>$ helm create my-chart\n</code></pre></p> <p>This command generates a directory structure with default files: <pre><code>my-chart/\n  Chart.yaml          # Chart metadata\n  values.yaml         # Default configuration values\n  charts/             # Dependency charts\n  templates/          # Kubernetes resource templates\n</code></pre></p> Example Chart.yaml <pre><code>apiVersion: v2\nname: my-chart\nversion: 0.1.0\ndescription: A Helm chart for Kubernetes\n</code></pre> Advanced Helm Features <ul> <li>Hooks: Allow you to run scripts at specific points in a release lifecycle.</li> <li>Lifecycle Management: Manage the lifecycle of applications with upgrade and rollback capabilities.</li> <li>Managing Dependencies: Use the <code>requirements.yaml</code> file to manage chart dependencies.</li> </ul> Customizing Helm Charts <p>Customize charts for different environments by using values files and templates to override default settings.</p>"},{"location":"helm-package-management/#best-practices","title":"Best Practices","text":"<ul> <li>Version Control: Keep your charts in version control for easy tracking and collaboration.</li> <li>Testing: Test your charts in different environments to ensure compatibility.</li> <li>Security: Regularly update your charts to include the latest security patches.</li> <li>Documentation: Provide clear documentation for using and customizing your charts.</li> </ul>"},{"location":"kubernetes-api/","title":"Kubernetes API","text":""},{"location":"kubernetes-api/#mastering-the-kubernetes-api","title":"Mastering the Kubernetes API","text":"<p>Understanding the Kubernetes API is essential for mastering Kubernetes. It serves as the backbone of the platform, allowing you to manage resources programmatically and automate cluster operations.</p>"},{"location":"kubernetes-api/#overview-of-the-kubernetes-api","title":"Overview of the Kubernetes API","text":"The Big Picture <p>Kubernetes is an API-centric platform. All resources, such as Pods, Services, and StatefulSets, are defined through the API and managed by the API server. Administrators and clients interact with the cluster by sending requests to create, read, update, and delete these resources. Most interactions are done using <code>kubectl</code>, but they can also be crafted in code or generated through API development tools.</p> Key Concepts <ul> <li>API Server: The central component that exposes the API and handles requests.</li> <li>Resources and Objects: Resources like Pods and Services are defined in the API. When deployed to a cluster, these resources are often called objects.</li> <li>Serialization: The process of converting an object into a string or stream of bytes for transmission or storage. Kubernetes supports JSON and Protobuf for serialization.</li> </ul> API Versioning and Stability <p>Kubernetes uses API versioning to manage changes and ensure stability. Versions are indicated by paths such as <code>/api/v1</code> or <code>/apis/apps/v1</code>.</p> <ul> <li>Alpha: Early-stage features, subject to change, not recommended for production.</li> <li>Beta: More stable, but still subject to change; suitable for testing.</li> <li>Stable: Well-tested and reliable, safe for production use.</li> </ul>"},{"location":"kubernetes-api/#using-the-kubernetes-api","title":"Using the Kubernetes API","text":"Interacting with the API <p>You can interact with the Kubernetes API using various tools and libraries:</p> <ul> <li><code>kubectl</code>: The command-line tool for interacting with the API server.</li> <li><code>curl</code>: Use for direct HTTP requests to the API server.</li> <li>Client Libraries: Available for multiple languages, including Go, Python, and Java.</li> </ul> Example: Using `curl` to Access the API <pre><code># List all Pods in the default namespace\ncurl -X GET http://localhost:8001/api/v1/namespaces/default/pods\n</code></pre> Creating Custom Resources <p>For detailed information on creating and managing Custom Resource Definitions (CRDs), please refer to the Operators and CRDs section. This section provides comprehensive guidance on extending the Kubernetes API with custom resources tailored to your application's needs.</p>"},{"location":"kubernetes-api/#best-practices","title":"Best Practices","text":"<ul> <li>Secure API Access: Use TLS and authentication to secure communication with the API server.</li> <li>Manage API Tokens: Regularly rotate and manage API tokens to ensure security.</li> <li>Monitor API Usage: Keep track of API usage to optimize performance and detect anomalies.</li> </ul>"},{"location":"kubernetes-api/#understanding-serialization","title":"Understanding Serialization","text":"<p>Serialization is essential for transmitting and storing objects. Kubernetes typically uses JSON for communication with external clients and Protobuf for internal cluster traffic due to its efficiency.</p> Example: Serialization in Action <p>When a client like <code>kubectl</code> posts a request, it serializes the object as JSON. The API server then processes this request and sends back a serialized response.</p>"},{"location":"kubernetes-api/#the-api-server","title":"The API Server","text":"Role and Function <p>The API server is the front-end to the Kubernetes API, handling all RESTful HTTPS requests. It manages all interactions between internal components and external clients.</p> Components <ul> <li>Control Plane Service: Runs as a set of Pods in the <code>kube-system</code> Namespace.</li> <li>TLS and Authentication: Ensures secure communication and validates requests.</li> <li>RESTful Interface: Supports CRUD operations via standard HTTP methods (POST, GET, PUT, PATCH, DELETE).</li> </ul> Example: Using the API <p>A typical <code>kubectl</code> command translates into a REST request: <pre><code>kubectl get pods --namespace eggs\n</code></pre> This command converts to: <pre><code>GET /api/v1/namespaces/eggs/pods\n</code></pre></p>"},{"location":"kubernetes-api/#hands-on-with-the-api","title":"Hands-On with the API","text":"Exploring the API <p>1. Start a Proxy Session: <pre><code>kubectl proxy --port 9000 &amp;\n</code></pre>    This command starts a local proxy to the Kubernetes API server, allowing you to interact with the API using <code>curl</code> or other HTTP clients on <code>http://localhost:9000</code>.</p> <p>2. Using <code>curl</code> to Interact with the API: <pre><code>curl -X GET http://localhost:9000/api/v1/namespaces/eggs/pods\n</code></pre>    This command sends a GET request to the API server to retrieve information about Pods in the <code>eggs</code> Namespace.</p> <p>Example output: <pre><code>{\n  \"kind\": \"PodList\",\n  \"apiVersion\": \"v1\",\n  \"items\": []\n}\n</code></pre></p> Creating Resources <p>1. Define a Namespace:    Create a JSON file (<code>ns.json</code>):    <pre><code>{\n  \"kind\": \"Namespace\",\n  \"apiVersion\": \"v1\",\n  \"metadata\": {\n    \"name\": \"eggs\",\n    \"labels\": {\n      \"chapter\": \"api\"\n    }\n  }\n}\n</code></pre></p> <p>2. Post the Namespace: <pre><code>curl -X POST -H \"Content-Type: application/json\" --data-binary @ns.json http://localhost:9000/api/v1/namespaces\n</code></pre>    This command posts the JSON data to the API server, creating a new Namespace called <code>eggs</code>.</p> <p>Example output: <pre><code>{\n  \"kind\": \"Namespace\",\n  \"apiVersion\": \"v1\",\n  \"metadata\": {\n    \"name\": \"eggs\",\n    \"selfLink\": \"/api/v1/namespaces/eggs\",\n    \"uid\": \"abcd1234-5678-90ef-ghij-klmnopqrstuv\",\n    \"resourceVersion\": \"123456\",\n    \"creationTimestamp\": \"2024-06-07T12:34:56Z\",\n    \"labels\": {\n      \"chapter\": \"api\"\n    }\n  }\n}\n</code></pre></p> <p>3. Verify Creation: <pre><code>kubectl get namespaces\n</code></pre>    This command lists all Namespaces in the cluster, allowing you to verify the creation of the <code>eggs</code> Namespace.</p> <p>Example output: <pre><code>NAME          STATUS   AGE\ndefault       Active   84d\nkube-system   Active   84d\neggs          Active   1m\n</code></pre></p> <p>4. Delete the Namespace: <pre><code>curl -X DELETE http://localhost:9000/api/v1/namespaces/eggs\n</code></pre>    This command deletes the <code>eggs</code> Namespace.</p> <p>Example output: <pre><code>{\n  \"kind\": \"Namespace\",\n  \"apiVersion\": \"v1\",\n  \"metadata\": {\n    \"name\": \"eggs\",\n    \"deletionTimestamp\": \"2024-06-07T12:36:00Z\"\n  },\n  \"status\": {\n    \"phase\": \"Terminating\"\n  }\n}\n</code></pre></p>"},{"location":"kubernetes-api/#inspecting-the-api","title":"Inspecting the API","text":"Useful Commands <p>1. List All API Resources: <pre><code>kubectl api-resources\n</code></pre>    This command lists all available API resources in the cluster.</p> <p>Example output: <pre><code>NAME                  SHORTNAMES   APIGROUP                       NAMESPACED   KIND\npods                  po                                        true          Pod\nservices              svc                                       true          Service\ndeployments           deploy        apps                        true          Deployment\n...\n</code></pre></p> <p>2. List Supported API Versions: <pre><code>kubectl api-versions\n</code></pre>    This command lists all API versions supported by the cluster.</p> <p>Example output: <pre><code>v1\napps/v1\nbatch/v1\nextensions/v1beta1\n...\n</code></pre></p> <p>3. Inspect Specific Resources: <pre><code>kubectl explain pods\n</code></pre>    This command provides detailed information about the <code>Pod</code> resource, including its fields and their descriptions.</p> <p>Example output: <pre><code>KIND:     Pod\nVERSION:  v1\n\nDESCRIPTION:\n     Pod is a collection of containers that can run on a host. This resource\n     is created by clients and scheduled onto hosts.\n\nFIELDS:\n   apiVersion   &lt;string&gt;\n   kind         &lt;string&gt;\n   metadata     &lt;Object&gt;\n   spec         &lt;Object&gt;\n   status       &lt;Object&gt;\n</code></pre></p> <p>4. Using <code>curl</code> to Explore: <pre><code>curl http://localhost:9000/apis\n</code></pre>    This command lists all API groups and their versions available in the cluster.</p> <p>Example output: <pre><code>{\n  \"kind\": \"APIGroupList\",\n  \"apiVersion\": \"v1\",\n  \"groups\": [\n    {\n      \"name\": \"apps\",\n      \"versions\": [\n        {\n          \"groupVersion\": \"apps/v1\",\n          \"version\": \"v1\"\n        }\n      ],\n      \"preferredVersion\": {\n        \"groupVersion\": \"apps/v1\",\n        \"version\": \"v1\"\n      }\n    },\n    ...\n  ]\n}\n</code></pre></p>"},{"location":"kubernetes-api/#extending-the-api","title":"Extending the API","text":"Custom Resources <p>Kubernetes allows you to extend the API with CustomResourceDefinitions (CRDs). These custom resources behave like native Kubernetes resources, enabling you to manage new types of objects within your cluster. Please see the Operators and CRDs section for more information on working with CRDs.</p>"},{"location":"kubernetes-api/#summary","title":"Summary","text":"<p>The Kubernetes API is a powerful tool for managing your cluster. By understanding its structure and capabilities, you can leverage it to automate and streamline your operations. From creating resources to extending the API with custom definitions, mastering the API is key to unlocking Kubernetes' full potential.</p>"},{"location":"local-setup/","title":"Local Setup","text":""},{"location":"local-setup/#getting-a-local-kubernetes-cluster","title":"Getting a Local Kubernetes Cluster","text":"<p>For most users, setting up a local Kubernetes cluster using Docker Desktop or KinD (Kubernetes in Docker) is the best option when learning. It's free and allows you to quickly and easily get your hands on and start playing with Kubernetes.</p> Option 1: Docker Desktop <p>Docker Desktop is a straightforward way to get Docker, Kubernetes, and <code>kubectl</code> on your computer, along with a user-friendly interface for managing your cluster contexts.</p> <p>Install Docker Desktop:</p> <p>Download and run the installer for your operating system from the Docker website. Follow the installation prompts. For Windows users, install the WSL 2 subsystem when prompted.</p> <p>Enable Kubernetes in Docker Desktop:</p> <p>Click the Docker icon in your menu bar or system tray and go to Settings. Select \"Kubernetes\" from the left navigation bar. Check \"Enable Kubernetes\" and click \"Apply &amp; restart.\" Wait a few minutes for Docker Desktop to pull the required images and start the cluster. The Kubernetes icon in the Docker Desktop window will turn green when the cluster is ready.</p> <p>Verify the Installation:</p> <p>Open a terminal and run the following commands to ensure Docker and <code>kubectl</code> are installed and working:</p> <pre><code>docker --version\nkubectl version --client=true -o yaml\n</code></pre> <p>Ensure the cluster is running with:</p> <p><pre><code>kubectl get nodes\n</code></pre> This command lists all the nodes in your Kubernetes cluster. You should see at least one node listed, confirming your cluster is up and running.</p> Option 2: KinD <p>KinD (Kubernetes in Docker) is an excellent tool for running local Kubernetes clusters using Docker containers. It\u2019s lightweight, flexible, and ideal for development and testing. It's my tool of choice for local development/experimentation.</p> <p>Install KinD:</p> <p>Follow the instructions on the KinD GitHub page to install KinD on your system. For macOS users, you can simply run <code>brew install kind</code> to get up and running quickly.</p> <p>Create a KinD Cluster:</p> <p><pre><code>kind create cluster\n</code></pre> This command sets up a new Kubernetes cluster locally using Docker containers. KinD creates a single-node cluster by default, which is sufficient for most development and testing needs.</p> <p>Verify your cluster is running:</p> <p><pre><code>kubectl get nodes\n</code></pre> This command lists all the nodes in your Kubernetes cluster. You should see the node created by KinD, confirming your cluster is up and running.</p> Alternative Tools <p>While Docker Desktop and KinD are popular choices, other tools like Minikube or k3d can also be used to set up local Kubernetes clusters. These tools offer different features and may better suit specific needs or preferences.</p>"},{"location":"local-setup/#working-with-kubectl","title":"Working with kubectl","text":"<p><code>kubectl</code> is the command-line tool used to interact with your Kubernetes clusters. It's essential for deploying applications, inspecting and managing cluster resources, and troubleshooting issues.</p> Installation <p>If you've followed the steps to set up either Docker Desktop or KinD, you should already have <code>kubectl</code> installed. If not, you can install it separately:</p> <p>Linux:</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin/\n</code></pre> <p>Mac:</p> <pre><code>brew install kubectl\n</code></pre> <p>Windows:</p> <p>Download the executable from the official Kubernetes site and add it to your system PATH.</p> Using kubectl <p>Once installed, <code>kubectl</code> allows you to perform various operations on your Kubernetes cluster. Here are a few basic commands to get you started:</p> <p>Check Cluster Nodes: <pre><code>kubectl get nodes\n</code></pre> This command lists all nodes in the cluster, showing their status, roles, and other details.</p> <p>Get Cluster Info: <pre><code>kubectl cluster-info\n</code></pre> This command displays information about the cluster, including the URL of the Kubernetes master and other components.</p> <p>Deploy an Application: <pre><code>kubectl apply -f &lt;filename&gt;.yaml\n</code></pre> This command applies a configuration file to the cluster, creating or updating resources defined in the file.</p> <p>Inspect Resources: <pre><code>kubectl get pods\nkubectl describe pod &lt;pod-name&gt;\n</code></pre> These commands list all pods in the cluster and provide detailed information about a specific pod, respectively.</p> Setting an Alias for kubectl <p>Instead of typing out <code>kubectl</code> for every command, many Kubernetes users set an alias for it by adding the following to their shell profile:</p> <p><pre><code>alias k=kubectl\n</code></pre> This way, you can use <code>k</code> instead of <code>kubectl</code> in your commands, saving time and effort.</p> <p>Tip</p> <p>Using aliases can significantly speed up your workflow and reduce the chances of making typos in long commands.</p>"},{"location":"local-setup/#summary","title":"Summary","text":"<p>Setting up a local Kubernetes cluster using Docker Desktop or KinD is a great way to get hands-on experience with Kubernetes. Both tools provide an easy and quick way to start working with Kubernetes, allowing you to experiment and learn in a controlled environment. With <code>kubectl</code>, you can manage your cluster and deploy applications, making it an essential tool for any Kubernetes user.</p>"},{"location":"maintenance/","title":"Kubernetes Maintenance","text":"<p>Regular maintenance is essential for ensuring the stability and performance of your Kubernetes clusters. This section covers key maintenance activities, including upgrading clusters, nodes, Kubernetes versions, and operating systems.</p>"},{"location":"maintenance/#upgrading-kubernetes-clusters","title":"Upgrading Kubernetes Clusters","text":"Cluster Upgrades <p>Upgrading your Kubernetes cluster ensures you have the latest features, security patches, and performance improvements.</p> <ol> <li> <p>Plan the Upgrade</p> <ul> <li>Review release notes and determine upgrade path.</li> <li>Backup critical data and verify integrity.</li> <li>Test the upgrade process in a staging environment.</li> </ul> </li> <li> <p>Perform the Upgrade</p> <ul> <li>Follow your Kubernetes distribution's upgrade documentation.</li> <li>Monitor the upgrade process and be ready to roll back if needed.</li> </ul> </li> </ol> Node Upgrades <ol> <li> <p>Prepare Nodes</p> <ul> <li>Drain nodes using <code>kubectl drain &lt;node-name&gt;</code>.</li> <li>Upgrade Kubernetes components and OS packages.</li> </ul> </li> <li> <p>Rejoin Cluster</p> <ul> <li>Use <code>kubectl uncordon &lt;node-name&gt;</code> to bring nodes back online.</li> </ul> </li> </ol>"},{"location":"maintenance/#upgrading-kubernetes-versions","title":"Upgrading Kubernetes Versions","text":"<ol> <li> <p>Check Compatibility</p> <ul> <li>Review the version skew policy to ensure compatibility across your environment.</li> <li>Review deprecated features and update manifests.</li> <li>Test applications in a staging environment.</li> </ul> </li> <li> <p>Upgrade Control Plane and Nodes</p> <ul> <li>Follow official Kubernetes documentation for upgrading components.</li> <li>Upgrade <code>kubelet</code> and <code>kubectl</code> on nodes.</li> </ul> </li> </ol>"},{"location":"maintenance/#best-practices","title":"Best Practices","text":"<ul> <li>Regularly audit cluster configurations and security settings.</li> <li>Document maintenance activities and changes.</li> <li>Implement automated backup solutions to protect critical data.</li> </ul>"},{"location":"namespaces/","title":"Kubernetes Namespaces","text":"<p>Namespaces provide a way to divide cluster resources between multiple users. They are intended for use in environments with many users spread across multiple teams, or projects.</p>"},{"location":"namespaces/#understanding-namespaces","title":"Understanding Namespaces","text":"Purpose of Namespaces <p>Namespaces allow you to create multiple virtual clusters within the same physical cluster. They help in organizing and managing resources efficiently.</p> Common Use Cases <ul> <li>Environment Separation: Separate development, testing, and production environments.</li> <li>Resource Quotas: Apply resource limits to different teams or projects.</li> <li>Access Control: Implement fine-grained access control using Role-Based Access Control (RBAC).</li> </ul>"},{"location":"namespaces/#managing-namespaces","title":"Managing Namespaces","text":"Creating a Namespace <pre><code>kubectl create namespace dev\n</code></pre> Viewing Namespaces <pre><code>kubectl get namespaces\n</code></pre> Deleting a Namespace <pre><code>kubectl delete namespace dev\n</code></pre> Advanced Namespace Management <p>Namespaces can be used to implement advanced management strategies:</p> <ul> <li>Network Policies: Control traffic flow between namespaces to enhance security.</li> <li>Custom Resource Definitions (CRDs): Use CRDs to extend namespace capabilities with custom resources.</li> <li>Monitoring and Logging: Implement monitoring solutions to track resource usage and access patterns across namespaces.</li> </ul> Example: Network Policies for Namespaces <p>Network policies can be applied to namespaces to control traffic flow. Here's an example:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-namespace\n  namespace: dev\nspec:\n  podSelector:\n    matchLabels: {}\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: frontend\n</code></pre> <p>This policy allows traffic from Pods in the <code>frontend</code> namespace to Pods in the <code>dev</code> namespace.</p>"},{"location":"namespaces/#best-practices","title":"Best Practices","text":"<ul> <li>Consistent Naming: Use a consistent naming convention for namespaces.</li> <li>Limit Resource Usage: Apply resource quotas and limits to manage resource consumption.</li> <li>Regular Audits: Conduct regular audits to ensure compliance with policies.</li> </ul>"},{"location":"operators-crds/","title":"Kubernetes Operators and Custom Resource Definitions (CRDs)","text":"<p>Kubernetes Operators and CRDs extend the functionality of Kubernetes by allowing you to manage complex applications and define custom resources tailored to your needs.</p>"},{"location":"operators-crds/#understanding-operators","title":"Understanding Operators","text":"What are Operators? <p>Operators are software extensions that use custom resources to manage applications and their components. They automate tasks beyond the capabilities of standard Kubernetes resources, following Kubernetes principles like the control loop.</p> Purpose of Operators <p>Operators automate the lifecycle of complex applications, including:</p> <ul> <li>Installation: Deploying and configuring applications.</li> <li>Management: Managing runtime configurations.</li> <li>Scaling: Adjusting resources based on workloads.</li> <li>Healing: Detecting and recovering from failures.</li> <li>Upgrades: Updating applications to new versions.</li> </ul> Benefits of Using Operators <ul> <li>Consistency: Provides a consistent way to manage applications.</li> <li>Automation: Reduces manual intervention.</li> <li>Scalability: Manages resources efficiently.</li> </ul> Advanced Operator Features <ul> <li>Event Handling: Operators can respond to Kubernetes events to maintain desired state.</li> <li>Custom Metrics: Use custom metrics to make informed scaling decisions.</li> <li>Backup and Restore: Implement application-specific backup and restore logic.</li> </ul>"},{"location":"operators-crds/#understanding-custom-resource-definitions-crds","title":"Understanding Custom Resource Definitions (CRDs)","text":"Introduction to CRDs <p>CRDs allow you to define custom resources within the Kubernetes API, enabling the management of application-specific data and configurations.</p> Benefits of Using CRDs <ul> <li>Custom Resources: Tailor resources to your application's needs.</li> <li>Declarative Management: Use Kubernetes' API for management.</li> <li>Integration: Seamlessly integrate with Kubernetes tools.</li> </ul> Advanced CRD Features <ul> <li>Schema Validation: Define validation rules for custom resources to ensure data integrity.</li> <li>Versioning: Manage different versions of CRDs to support application evolution.</li> <li>Subresources: Use subresources like status and scale for additional functionality.</li> </ul> Creating a CRD <p>Define a CRD in a YAML file and apply it to your cluster.</p> <p>Example CRD Definition: <pre><code>apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: widgets.example.com\nspec:\n  group: example.com\n  versions:\n    - name: v1\n      served: true\n      storage: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                size:\n                  type: string\n                color:\n                  type: string\n  scope: Namespaced\n  names:\n    plural: widgets\n    singular: widget\n</code></pre></p>"},{"location":"operators-crds/#creating-and-deploying-operators","title":"Creating and Deploying Operators","text":"Developing an Operator <p>Develop an Operator by defining custom resources and implementing controllers.</p> <pre><code># Install the Operator SDK\ncurl -LO https://github.com/operator-framework/operator-sdk/releases/download/v1.0.0/operator-sdk_linux_amd64\nchmod +x operator-sdk_linux_amd64\nsudo mv operator-sdk_linux_amd64 /usr/local/bin/operator-sdk\n\n# Create a new Operator project\noperator-sdk init --domain=example.com --repo=github.com/example-inc/memcached-operator\n\n# Define a new API\noperator-sdk create api --group cache --version v1alpha1 --kind Memcached --resource --controller\n</code></pre>"},{"location":"operators-crds/#best-practices","title":"Best Practices","text":"<ul> <li>Version Control: Use version control for Operator code and CRDs.</li> <li>Testing: Implement thorough testing to ensure reliability.</li> <li>Documentation: Provide clear documentation for usage and maintenance.</li> <li>Security: Follow security best practices to protect data and configurations.</li> </ul>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#introduction-to-kubernetes","title":"Introduction to Kubernetes","text":"<p>Kubernetes, often referred to as K8s, is an open-source platform designed to automate deploying, scaling, and operating application containers. Originally developed by Google, it is now maintained by the Cloud Native Computing Foundation (CNCF). This section provides an essential overview of Kubernetes, its architecture, and key features to get you started.</p>"},{"location":"overview/#what-is-kubernetes","title":"What is Kubernetes?","text":"<p>Kubernetes is a powerful container orchestrator that manages the deployment and operation of containerized applications. Containers are lightweight, portable units that bundle an application and its dependencies, allowing them to run consistently across different environments. Kubernetes automates several tasks:</p> <ul> <li>Deployment: Seamlessly deploys applications by creating and managing containers.</li> <li>Scaling: Adjusts the number of application instances based on demand, ensuring efficient use of resources.</li> <li>Self-healing: Detects and replaces failed instances to maintain application availability.</li> <li>Rolling Updates and Rollbacks: Updates applications without downtime and rolls back to a previous version if needed.</li> </ul>"},{"location":"overview/#key-concepts-of-kubernetes","title":"Key Concepts of Kubernetes","text":"Declarative Model <p>Kubernetes operates on a declarative model, where you specify the desired state of the system in YAML or JSON configuration files. The system continuously works to ensure the observed state matches the desired state. This involves three key principles:</p> <ol> <li>Observed State: The current state of the system.</li> <li>Desired State: The state you want the system to achieve.</li> <li>Reconciliation: The process of adjusting the observed state to match the desired state.</li> </ol> <p>The declarative nature of Kubernetes is key to understanding its power. At a high level, here's how it works:</p> <ol> <li>You tell Kubernetes (typically via <code>kubectl</code>) how you want your application to look\u2014what image to use, how many replicas, ports to expose, etc.</li> <li>Kubernetes persists this desired state to the cluster store (etcd).</li> <li>A series of background controllers consistently check if the current state matches the desired state.</li> <li>If the current state does not equal the desired state (e.g., you desire 3 replicas but only 2 are currently running), the API Server is notified and,</li> <li>Kubernetes initiates actions to reconcile the two states.</li> </ol> Declarative Approach in Kubernetes <p>Kubernetes uses a declarative approach to manage resources. This means you define the desired state of the system and Kubernetes works to maintain that state.</p> <pre><code>sequenceDiagram\n    participant User\n    participant APIServer as API Server\n    participant etcd\n    participant Controller as Controller Manager\n    participant Scheduler\n\n    User-&gt;&gt;APIServer: 1. Declare desired state\n    APIServer-&gt;&gt;etcd: 2. Persist desired state\n\n    Controller-&gt;&gt;APIServer: 3. Check actual vs. desired\n    APIServer--&gt;&gt;Controller: current != desired\n    Controller-&gt;&gt;APIServer: Reconcile differences\n\n    APIServer-&gt;&gt;Scheduler: Trigger scheduling if needed</code></pre> <p>This diagram illustrates how Kubernetes manages resources declaratively, ensuring the system's state aligns with the user's specifications.</p> Kubernetes Architecture <p>Kubernetes architecture consists of several key components:</p> <ul> <li>API Server: The front-end for the Kubernetes control plane, handling all REST operations.</li> <li>etcd: A consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data.</li> <li>Scheduler: Assigns workloads to nodes based on resource availability.</li> <li>Controller Manager: Runs controllers to regulate the state of the cluster.</li> <li>Kubelet: Ensures containers are running in a Pod on each node.</li> </ul> Services <p>Services provide stable networking endpoints for Pods, enabling reliable communication between different parts of an application. They abstract away the ephemeral nature of Pods, which can be created and destroyed dynamically, and give you a stable, long-lived connection point to the underlying Pods.</p>"},{"location":"overview/#historical-background","title":"Historical Background","text":"<p>Kubernetes was born from Google's internal systems like Borg and Omega, which managed containerized applications like Search and Gmail at a massive scale. In 2014, Google open-sourced Kubernetes, and it quickly became the standard for container orchestration.</p>"},{"location":"overview/#common-features-primer","title":"Common Features Primer","text":"Pods and Deployments <ul> <li>Pods: The smallest deployable units in Kubernetes, which can contain one or more containers. Containers within Pods share resources like network and storage.</li> <li>Deployments: Higher-level controllers that manage Pods, providing features like scaling, rolling updates, and rollbacks.</li> </ul> Self-Healing and Scaling <p>If deployed as part of a Deployment or StatefulSet, Kubernetes will automatically replace failed Pods and scale your application up or down based on traffic, load, or other custom thresholds. This ensures high availability and efficient resource utilization.</p> Rolling Updates and Rollbacks <p>By leveraging Deployments (via ReplicaSets), Kubernetes allows you to update your application without downtime by gradually replacing old Pods with new ones. If something goes wrong, Kubernetes can roll back to the previous version.</p>"},{"location":"overview/#summary","title":"Summary","text":"<p>Kubernetes is a powerful tool for managing containerized applications, offering automation, scalability, and reliability. By abstracting the underlying infrastructure, it simplifies application deployment and management across various environments. Whether you're running on-premises or in the cloud, Kubernetes provides a consistent and efficient platform for your applications. Before diving into some more details on these topics, let's first cover how you can quickly get your hands on a Kubernetes environment in the next section.</p>"},{"location":"pods-deployments/","title":"Pods and Deployments","text":""},{"location":"pods-deployments/#introduction-to-kubernetes-pods","title":"Introduction to Kubernetes Pods","text":"<p>In Kubernetes, every application runs inside a Pod. Understanding how to work with Pods is crucial for deploying, scaling, and managing applications effectively.</p> Pod Fundamentals <p>Pods are the smallest deployable units in Kubernetes and serve as an abstraction layer, allowing various types of workloads to run seamlessly. They enable resource sharing, advanced scheduling, health monitoring, and more.</p> Abstraction and Benefits <p>Pods abstract the complexities of different workload types, enabling Kubernetes to manage them without needing to understand the specifics of each workload. This abstraction allows for uniform deployment and management across heterogeneous environments.</p> Enhancements and Capabilities <p>Pods offer several enhancements for containers, including:</p> <ul> <li>Resource Sharing: Shared filesystem, network stack, memory, process tree, and hostname.</li> <li>Advanced Scheduling: Features like nodeSelectors, affinity rules, topology spread constraints, resource requests, and limits.</li> <li>Health Monitoring and Restart Policies: Probes for application health and policies for container restarts.</li> <li>Security and Termination Control: Enhanced security measures and graceful shutdown processes.</li> <li>Volumes: Shared storage among containers within a Pod.</li> </ul> <p></p> <pre><code>flowchart TD \nsubgraph \"Pod\"\n    subgraph \"container\"\n    H[\"application\"]\n    end\n    end</code></pre> <p>In the image above, you can have any sort of application running (Python, Java, MySQL, LLM, etc.), but once containerized and wrapped in a Pod, Kubernetes treats them all the same and doesn't have to worry about the details of how each application is written or works.</p> <p></p> Detailed Pod Lifecycle <ul> <li>Pending: The Pod has been accepted by the Kubernetes system, but one or more of the container images has not been created. This includes time before being scheduled as well as time spent downloading images over the network, which could take a while.</li> <li>Running: The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting.</li> <li>Succeeded: All containers in the Pod have terminated in success, and will not be restarted.</li> <li>Failed: All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system.</li> <li>Unknown: For some reason the state of the Pod could not be obtained, typically due to an error in communicating with the host of the Pod.</li> </ul> Multi-Container Pods <p>Multi-container Pods follow the single responsibility principle, where each container performs a distinct role. Some example use cases for this pattern include:</p> <ul> <li>Init Containers: Prepare the environment before application containers start.</li> <li>Sidecar Containers: Provide auxiliary services alongside the main application container.</li> </ul> <p>One common example is to use a multi-container Pod for service meshes. In these scenarios, a sidecar container acts as an SSL termination point for all traffic coming into the main Pod.</p> <p>Multiple containers within a Pod share the same IP address, network stack, and filesystem. As such, to communicate with specific containers within a multi-container Pod, you have to leverage port addresses. The containers themselves, however, will be able to communicate with each other via localhost.</p> <p></p>"},{"location":"pods-deployments/#kubernetes-deployments","title":"Kubernetes Deployments","text":"<p>Deployments in Kubernetes provide powerful capabilities for managing stateless applications. They enable features like self-healing, scaling, rolling updates, and versioned rollbacks, making it easier to maintain robust and scalable applications.</p> Key Concepts of Deployments <p>A Deployment in Kubernetes is a resource that manages a set of identical Pods, ensuring they are up and running as specified. Deployments provide a declarative way to manage updates and scaling of applications.</p> Why Use Deployments? <p>Deployments add several benefits to managing applications:</p> <ul> <li>Self-Healing: Automatically replaces failed Pods.</li> <li>Scaling: Adjusts the number of running Pods based on demand.</li> <li>Rolling Updates: Updates Pods without downtime.</li> <li>Rollbacks: Easily revert to previous versions if something goes wrong.</li> </ul> Deployment Strategies <ul> <li>Recreate: Terminates all existing Pods before creating new ones.</li> <li>Rolling Update: Gradually replaces Pods one by one to avoid downtime.</li> </ul> Detailed Deployment Process <ol> <li>Create a Deployment: Define your Deployment in a YAML file and use <code>kubectl apply</code> to create it.</li> <li>Monitor the Deployment: Use <code>kubectl get deployments</code> to check the status and ensure it's running as expected.</li> <li>Update the Deployment: Modify the YAML file and apply changes using <code>kubectl apply</code>.</li> <li>Rollback if Necessary: Use <code>kubectl rollout undo</code> to revert to a previous version if needed.</li> </ol>"},{"location":"pods-deployments/#creating-and-managing-deployments","title":"Creating and Managing Deployments","text":"<p>You can create a Deployment using a YAML file that specifies the configuration.</p> <p>Example YAML for Deployment:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example\n        image: nginx\n</code></pre> <p>This configuration creates a Deployment that manages 3 replicas of an Nginx Pod.</p>"},{"location":"security/","title":"Securing Kubernetes: Authentication, Authorization, and Admission Control","text":"<p>Kubernetes security is a critical aspect of managing clusters, ensuring that only authorized users and processes can access and modify resources. This section covers API security, Role-Based Access Control (RBAC), and admission control.</p>"},{"location":"security/#overview-of-kubernetes-security","title":"Overview of Kubernetes Security","text":"The Big Picture <p>Kubernetes is API-centric, with the API server as its core component. Every interaction with the cluster, whether from users, Pods, or internal services, goes through the API server. This makes securing the API server paramount.</p> Typical API Request Flow <p>A typical API request, such as creating a Deployment, follows these steps:</p> <ol> <li>Authentication: Verifies the identity of the requester.</li> <li>Authorization: Checks if the authenticated user has permission to perform the action.</li> <li>Admission Control: Ensures the request complies with policies.</li> </ol>"},{"location":"security/#authentication-authn","title":"Authentication (AuthN)","text":"Understanding Authentication <p>Authentication (authN) is about proving your identity. Kubernetes does not have a built-in identity database; instead, it integrates with external identity management systems. Common methods include:</p> <ul> <li>Client Certificates: Signed by the cluster's Certificate Authority (CA).</li> <li>Webhook Token Authentication: Integrates with external systems.</li> <li>Service Accounts: For intra-cluster communication.</li> </ul> Checking Your Authentication Setup <p>Your cluster's details and user credentials are stored in a <code>kubeconfig</code> file, typically located at: <code>/home/&lt;user&gt;/.kube/config</code></p> <p>Example <code>kubeconfig</code> File: <pre><code>apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    name: prod-eggs\n    server: https://&lt;api-server-url&gt;:443\n    certificate-authority-data: LS0mRS1F...LS0tRj==\nusers:\n- name: vinny\n  user:\n    token: FfqwFGF1gASDF4...SZY3uUQ\ncontexts:\n- context:\n    name: eggs-admin\n    cluster: prod-eggs\n    user: vinny\ncurrent-context: eggs-admin\n</code></pre></p> Integrating with External IAM Systems <p>Most production clusters integrate with enterprise-grade Identity and Access Management (IAM) systems such as Active Directory or cloud-based IAM solutions, providing robust authentication mechanisms.</p>"},{"location":"security/#authorization-authz","title":"Authorization (AuthZ)","text":"Understanding Authorization <p>Authorization (authZ) determines what actions authenticated users can perform. Kubernetes uses a least-privilege model with deny-by-default, meaning you must explicitly grant permissions.</p> Role-Based Access Control (RBAC) <p>RBAC is a method of regulating access to computer or network resources based on the roles of individual users within your organization. Kubernetes RBAC allows you to dynamically configure policies through the Kubernetes API.</p> Setting Up RBAC <p>To set up RBAC, define roles and role bindings in YAML files.</p> <p>Example Role: <pre><code>kind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre></p> <p>Example RoleBinding: <pre><code>kind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: read-pods\n  namespace: default\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: \"\"\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: \"\"\n</code></pre></p> ClusterRoles and ClusterRoleBindings <p>ClusterRoles apply to all Namespaces, allowing for broader permissions management.</p> <p>Example ClusterRole: <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: read-deployments\nrules:\n- verbs: [\"get\", \"watch\", \"list\"]\n  apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n</code></pre></p> <p></p> <p>Example ClusterRoleBinding: <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: read-deployments\nsubjects:\n- kind: User\n  name: jambo\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: read-deployments\n  apiGroup: rbac.authorization.k8s.io\n</code></pre></p>"},{"location":"security/#admission-control","title":"Admission Control","text":"Understanding Admission Controllers <p>Admission controllers are plugins that govern and enforce how the cluster should react to requests. They can be used to set defaults, enforce policies, and perform validations.</p> Common Admission Controllers <ul> <li>NamespaceLifecycle: Prevents deletion of active namespaces.</li> <li>LimitRanger: Enforces resource usage limits.</li> <li>ResourceQuota: Ensures resource usage does not exceed specified limits.</li> </ul> Example: NodeRestriction <p>To check admission controllers in your cluster: <pre><code>$ kubectl describe pod kube-apiserver-docker-desktop -n kube-system | grep admission\n--enable-admission-plugins=NodeRestriction\n</code></pre></p>"},{"location":"security/#certificates-and-service-accounts","title":"Certificates and Service Accounts","text":"Using Client Certificates <p>Client certificates authenticate users and services within the cluster. They are stored in the kubeconfig file and verified by the API server.</p> <p>Example of creating a client certificate: <pre><code>openssl genrsa -out client.key 2048\nopenssl req -new -key client.key -out client.csr -subj \"/CN=my-user\"\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365\n</code></pre></p> Service Accounts <p>Service Accounts provide identities for Pods and controllers, enabling secure intra-cluster communication. Unlike user accounts, which are meant for human users, service accounts are intended for processes that run in Pods.</p> <p>Example ServiceAccount: <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: my-service-account\n  namespace: default\n</code></pre></p> Using a ServiceAccount in a Pod <p>To use a service account in a pod, specify the <code>serviceAccountName</code> field in the pod's spec. This binds the pod to the specified service account, allowing the pod to use the account's credentials to authenticate to the API server and other services.</p> <p>Example of a Pod using a ServiceAccount: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  serviceAccountName: my-service-account\n  containers:\n  - name: my-container\n    image: myimage\n</code></pre></p>"},{"location":"security/#practical-example","title":"Practical Example","text":"Deploying a \"Secure\" Application <p>1. Create a Namespace: <pre><code>$ kubectl create namespace secure-app\n</code></pre></p> <p>2. Create a ServiceAccount:</p> <pre><code># serviceaccount.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: secure-app-sa\n  namespace: secure-app\n</code></pre> <pre><code>$ kubectl apply -f serviceaccount.yaml\n</code></pre> <p>3. Deploy a Pod using the ServiceAccount:</p> <p><pre><code># pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-pod\n  namespace: secure-app\nspec:\n  serviceAccountName: secure-app-sa\n  containers:\n  - name: secure-container\n    image: nginx\n</code></pre> <pre><code>$ kubectl apply -f pod.yaml\n</code></pre></p> <p>4. Create a Role and RoleBinding:</p> <pre><code># role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: secure-app\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre> <pre><code># rolebinding.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\n  namespace: secure-app\nsubjects:\n- kind: ServiceAccount\n  name: secure-app-sa\n  namespace: secure-app\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <pre><code>$ kubectl apply -f role.yaml\n$ kubectl apply -f rolebinding.yaml\n</code></pre>"},{"location":"security/#best-practices","title":"Best Practices","text":"<ul> <li>Secure the API Server: Use TLS to encrypt communication with the API server.</li> <li>Implement Network Policies: Control traffic flow between Pods.</li> <li>Regularly Update Clusters: Keep Kubernetes and its components up to date.</li> <li>Use Secrets for Sensitive Data: Store sensitive information securely using Kubernetes Secrets.</li> </ul>"},{"location":"security/#summary","title":"Summary","text":"<p>Securing a Kubernetes cluster involves multiple layers of authentication, authorization, and admission control. By understanding and implementing these mechanisms, you can ensure that your cluster is protected from unauthorized access and that all actions comply with defined policies.</p>"},{"location":"services-networking/","title":"Services and Networking","text":"<p>Kubernetes Services are essential for ensuring reliable communication between Pods. They abstract the complexities of networking and provide stable endpoints for applications.</p>"},{"location":"services-networking/#introduction-to-kubernetes-services","title":"Introduction to Kubernetes Services","text":"Why Use Services? <p>Pods in Kubernetes are ephemeral; they can be created, destroyed, and rescheduled at any time due to various events such as scaling operations, rolling updates, rollbacks, and failures. This makes direct communication with Pods unreliable. Kubernetes Services address this issue by providing a stable endpoint for communication.</p>"},{"location":"services-networking/#how-services-work","title":"How Services Work","text":"<p>Services in Kubernetes provide a front end (DNS name, IP address, and port) that remains constant regardless of the state of the Pods behind it. They use label selectors to dynamically route traffic to healthy Pods that match the specified criteria.</p> Service Discovery <p>Kubernetes offers two primary modes of service discovery:</p> <ul> <li>Environment Variables: When a Pod is created, the kubelet adds environment variables for each active Service. These variables are accessible within the Pod and provide the Service's cluster IP and port.</li> <li>DNS: Kubernetes includes a DNS server that automatically assigns DNS names to Services. Pods can use these DNS names to communicate with Services.</li> </ul> Endpoint Management <p>Services use endpoints to track the IP addresses of the Pods that match their label selector. The kube-proxy component on each node watches for changes to Service and Endpoint objects, updating the iptables rules accordingly to ensure traffic is correctly routed.</p> Load Balancing <p>Kubernetes Services provide built-in load balancing across the Pods they manage. The kube-proxy component distributes incoming requests to the available Pods based on the chosen load balancing strategy, ensuring even distribution of traffic.</p>"},{"location":"services-networking/#types-of-kubernetes-services","title":"Types of Kubernetes ServicesClusterIPNodePortLoadBalancerExternalName","text":"<p>Kubernetes supports several types of Services, each suited to different use cases:</p> <p>Key Points:</p> <ul> <li>Internal IP and DNS name are automatically created.</li> <li>Accessible only from within the cluster (i.e. Pod to Pod).</li> <li>Ideal for internal applications that do not need external access.</li> </ul> <p>Label Selector Behavior</p> <p>When a Service uses label selectors to find Pods (e.g., <code>project: ab</code>), Pods must have ALL the labels specified in the selector to receive traffic. However, Pods can have additional labels beyond those required by the selector and will still receive traffic. This means that selectors work as an \"AND\" operation, not an \"OR\" operation.</p> <p>Example YAML:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-clusterip-service\nspec:\n  selector:\n    app: my-app\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8080\n</code></pre> <ol> <li>External client hits node on NodePort.</li> <li>Node forwards request to the ClusterIP of the Service.</li> <li>The Service picks a Pod from the list of healthy Pods in the EndpointSlice.</li> <li>The Pod receives the request.</li> </ol> <p></p> <p>Key Points:</p> <ul> <li>Allocates a port from a configurable range (default: 30000-32767).</li> <li>Accessible externally via <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>.</li> <li>Useful for exposing applications for development and testing purposes.</li> </ul> <p>Important NodePort Behavior</p> <p>When you access a NodePort service, you can connect to any node in the cluster on the NodePort, even if the target Pod is not running on that specific node. Kubernetes will automatically route the traffic to the appropriate Pod, regardless of which node it's running on.</p> <ol> <li>External client hits LoadBalancer Service on friendly DNS name.</li> <li>LoadBalancer forwards request to a NodePort.</li> <li>Node forwards request to the ClusterIP of the Service.</li> <li>The Service picks a Pod from the EndpointSlice.</li> <li>Forwards request to the selected Pod.</li> </ol> <p>Key Points:</p> <ul> <li>Automatically provisions an external load balancer.</li> <li>Provides a single IP address for external access.</li> <li>Suitable for production environments where high availability is required.</li> </ul> <p>Key Points:</p> <ul> <li>Does not use kube-proxy.</li> <li>Maps Service to an external DNS name.</li> <li>Useful for integrating external services into a cluster.</li> </ul> Comparison of Service Types Service Type Internal Access External Access Use Case ClusterIP Yes No Internal applications NodePort Yes Yes (via NodeIP) Development and testing LoadBalancer Yes Yes Production environments with high availability ExternalName No Yes (via DNS) Integrating external services"},{"location":"services-networking/#service-discovery","title":"Service Discovery","text":"<p>In terms of how an application then discovers other applications behind a Service, the flow looks like this:</p> <ol> <li>The new Service is registered with the cluster DNS (Service Registry).</li> <li>Your application wants to know the IP address of the Service so it provides the name to the cluster DNS for lookup.</li> <li>The cluster DNS returns the IP address of the Service.</li> <li>Your application now knows where to direct its request.</li> </ol> Practical Example of Service Discovery <p>Assume we have two applications on the same cluster - <code>ham</code> and <code>eggs</code>. Each application has their Pods fronted by a Service, which in turn each have their own ClusterIP.</p> <pre><code>kubectl get svc\n</code></pre> <p>Example output: <pre><code>NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nham-svc      ClusterIP   192.168.1.200               443/TCP   5d19h\neggs-svc     ClusterIP   192.168.1.208               443/TCP   5d19h\n</code></pre></p> <p>For <code>ham</code> to communicate with <code>eggs</code>, it needs to know two things:</p> <ol> <li>The name of the <code>eggs</code> application's Service (eggs-svc).</li> <li>How to convert that name to an IP address.</li> </ol> Steps for Service Discovery: <ol> <li>The application container's default gateway routes the traffic to the Node it is running on.</li> <li>The Node itself does not have a route to the Service network so it routes the traffic to the node kernel.</li> <li>The Node kernel recognizes traffic intended for the service network and routes the traffic to a healthy Pod that matches the label selector of the Service.</li> </ol>"},{"location":"services-networking/#networking-in-kubernetes","title":"Networking in Kubernetes","text":"<p>Networking is a fundamental aspect of Kubernetes, enabling communication between various components within a cluster and with the outside world. This section covers the Container Network Interface (CNI) and popular CNI plugins, as well as network policies for controlling pod communication.</p> Container Network Interface (CNI) What is CNI? <p>The Container Network Interface (CNI) is a specification and a set of libraries for configuring network interfaces in Linux containers. It ensures that when a container is created or deleted, its network resources are allocated and cleaned up properly.</p> Role of CNI in Kubernetes <p>Kubernetes uses CNI to manage networking for Pods. When a Pod is created, the CNI plugin is responsible for assigning the Pod an IP address, setting up the network interface, and ensuring connectivity both within the cluster and externally.</p> Popular CNI Plugins <p>Several CNI plugins are widely used in Kubernetes environments. Each offers different features and capabilities.</p> Calico <p>Calico provides secure network connectivity for containers, virtual machines, and native host-based workloads. It supports a range of features, including:</p> <ul> <li>Network Policy Enforcement: Allows you to define and enforce network policies.</li> <li>BGP for Routing: Uses Border Gateway Protocol (BGP) for high-performance routing.</li> <li>IP-in-IP and VXLAN Encapsulation: Supports various encapsulation methods for different networking needs.</li> </ul> Flannel <p>Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes. It creates an overlay network that allows Pods on different nodes to communicate with each other.</p> Weave Net <p>Weave Net provides a simple and secure network for Kubernetes clusters. It supports automatic encryption of Pod traffic and can be used to create a flat network topology.</p> Understanding Overlay Networking in Kubernetes <p>Overlay networking is a fundamental concept in Kubernetes that allows for the seamless communication of pods across different nodes within a cluster. This approach abstracts the underlying network infrastructure, providing a virtual network that connects all pods regardless of their physical location.</p> Key Components of the Overlay Network <ul> <li>Node Network: The physical network where the Kubernetes nodes are deployed.</li> <li>Pod Network: A logically separate, private CIDR block distinct from the node network.</li> </ul> Network Policies <p>Network Policies allow you to control the communication between Pods. They define rules that specify what traffic is allowed to and from Pods.</p> Creating Network Policies <p>Network Policies are created using YAML configuration files that specify the allowed traffic.</p> <p>Example YAML for Network Policy: <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-frontend\nspec:\n  podSelector:\n    matchLabels:\n      role: frontend\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          role: backend\n</code></pre></p> <p>This configuration allows ingress traffic to Pods with the label \"role: frontend\" from Pods with the label \"role: backend.\"</p>"},{"location":"services-networking/#ingress","title":"Ingress","text":"Understanding Ingress <p>Ingress allows external HTTP and HTTPS traffic to access services within the cluster. It provides a single entry point for multiple services and can manage SSL termination, load balancing, and name-based virtual hosting.</p> Configuring Ingress <ol> <li> <p>Create an Ingress Resource: Define rules for routing traffic to services.</p> </li> <li> <p>Use an Ingress Controller: Deploy an Ingress controller to manage traffic according to the rules.</p> </li> <li> <p>TLS Configuration: Secure traffic using TLS by specifying certificates in the Ingress resource.</p> </li> </ol> Example Ingress Resource <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: example-ingress\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: example-service\n            port:\n              number: 80\n</code></pre> Advanced Ingress Configuration <p>Ingress can be configured for advanced use cases, such as:</p> <ul> <li>Path-Based Routing: Direct traffic based on URL paths to different services.</li> <li>Name-Based Virtual Hosting: Host multiple domains on the same IP address.</li> <li>Load Balancing: Distribute traffic across multiple backend services.</li> </ul> Example: Path-Based Routing <p>Here's how to configure path-based routing with Ingress:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: path-example\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /service1\n        pathType: Prefix\n        backend:\n          service:\n            name: service1\n            port:\n              number: 80\n      - path: /service2\n        pathType: Prefix\n        backend:\n          service:\n            name: service2\n            port:\n              number: 80\n</code></pre> <p>This configuration routes traffic to <code>service1</code> and <code>service2</code> based on the URL path.</p>"},{"location":"statefulsets/","title":"StatefulSets","text":""},{"location":"statefulsets/#managing-stateful-applications-with-kubernetes-statefulsets","title":"Managing Stateful Applications with Kubernetes StatefulSets","text":"<p>StatefulSets are essential for deploying and managing stateful applications on Kubernetes, which require persistent storage and stable network identities. This includes databases, key-value stores, and applications that maintain client session data.</p>"},{"location":"statefulsets/#introduction-to-statefulsets","title":"Introduction to StatefulSets","text":"What are StatefulSets? <p>StatefulSets are a Kubernetes resource designed to manage stateful applications. Unlike Deployments, StatefulSets provide:</p> <ul> <li>Predictable and persistent Pod names</li> <li>Persistent DNS hostnames</li> <li>Persistent volume bindings</li> </ul> <p>These features ensure that each Pod maintains a consistent identity, even across restarts, failures, and rescheduling.</p> Use Cases for StatefulSets <p>StatefulSets are ideal for applications that require stable identities and persistent storage, such as:</p> <ul> <li>Databases (e.g., MySQL, PostgreSQL)</li> <li>Distributed systems (e.g., Kafka, Zookeeper)</li> <li>Applications maintaining client session data</li> </ul> Key Differences from Deployments <p>While both StatefulSets and Deployments are used to manage Pods, StatefulSets offer additional guarantees:</p> <ul> <li>Ordered Creation and Deletion: Pods are created and deleted in a specific order.</li> <li>Unique Network Identities: Each Pod gets a unique, stable network identity.</li> <li>Stable Storage: Each Pod is associated with persistent storage that remains consistent across restarts.</li> </ul> <p>StatefulSets are Kubernetes constructs designed to manage stateful applications that require persistent data and identity across Pod restarts and deployments. Each Pod in a StatefulSet is given a stable and unique network identifier and persistent storage, which remains associated with the Pod, even when it is rescheduled to a different node within the cluster.</p> <p>StatefulSets are Kubernetes tools for running and managing applications that need to remember who they are and what they know\u2014think of them like memory keepers for your apps, such as databases that need to recall data after a reboot. Unlike Deployments that are more about stateless apps (think of them as forgetful but easily replaceable), StatefulSets make sure each of their Pods has a consistent name, network identity, and storage, even if they move around in the cluster. This makes StatefulSets perfect for when your app's individual identity and history are crucial for running smoothly.</p> <p>StatefulSets can guarantee Pod names, volume bindings, and DNS hostnames across reboots - whereas Deployments cannot. Below are two diagrams that illustrate this point:</p> <p>Notice how with a Deployment, when a Pod is replaced it comes up with a new name, IP address, and its volume is no longer bound to it. With StatefulSets, the new Pod comes up looking exactly the same as the previous failed one.</p>"},{"location":"statefulsets/#comparison-of-deployments-and-statefulsets","title":"Comparison of Deployments and StatefulSets","text":"Feature Deployment StatefulSet Pod Identity Random and ephemeral Stable and persistent Storage Ephemeral by default Persistent with volume claims Network Identity No stable network identity Stable network identity with DNS Pod Ordering No guarantees Ordered creation and deletion Use Cases Stateless applications Stateful applications like databases Scaling Parallel scaling Ordered scaling Updates Rolling updates Rolling updates with partitioning <p>This table highlights the key differences between Deployments and StatefulSets, helping you choose the right controller based on your application's needs.</p>"},{"location":"statefulsets/#statefulset-theory","title":"StatefulSet Theory","text":"Pod Naming <p>Each Pod in a StatefulSet gets a predictable name, following the format <code>&lt;StatefulSetName&gt;-&lt;integer&gt;</code>. For example, a StatefulSet named <code>my-sts</code> with three replicas will have Pods named <code>my-sts-0</code>, <code>my-sts-1</code>, and <code>my-sts-2</code>.</p> Ordered Creation and Deletion <p>StatefulSets create and delete Pods in a specific order:</p> <ul> <li>Creation: Pods are created one at a time, waiting for each to be running and ready before creating the next.</li> <li>Deletion: Pods are deleted in reverse order, ensuring that the highest ordinal Pod is terminated first.</li> </ul> Volume Management <p>StatefulSets manage volumes through PersistentVolumeClaims (PVCs). Each Pod gets its own unique volume, which is preserved across restarts and reattachments:</p> <ul> <li>Volume Naming: Volumes are named based on the StatefulSet and Pod names, e.g., <code>vol-my-sts-0</code>, <code>vol-my-sts-1</code>.</li> <li>Persistence: Volumes remain attached to the same Pod, even if the Pod is rescheduled to a different node.</li> </ul>"},{"location":"statefulsets/#managing-statefulsets","title":"Managing StatefulSets","text":"Scaling StatefulSets <p>Scaling a StatefulSet involves adding or removing Pods in a controlled manner, ensuring that the order and identity of Pods are maintained.</p> <ul> <li>Scaling Up: New Pods are added in a sequential order.</li> <li>Scaling Down: Pods are removed in reverse order.</li> </ul> Updating StatefulSets <p>Updates to a StatefulSet are managed carefully to ensure application stability:</p> <ul> <li>Rolling Updates: Pods are updated one at a time, maintaining the order and identity.</li> <li>Partitioned Updates: Allows updates to a subset of Pods while others remain unchanged.</li> </ul> Example YAML for StatefulSet <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"statefulsets/#hands-on-with-statefulsets","title":"Hands-On with StatefulSets","text":"Deploying StatefulSets Example StatefulSet Configuration <p>Here\u2019s an example of a simple StatefulSet for a mysqlDB deployment:</p> <p>StatefulSet YAML: <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: my-sts\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mysql\n  serviceName: \"my-sts\"\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: ctr-mysql\n        image: mysql:latest\n        ports:\n        - containerPort: 3306\n  volumeClaimTemplates:\n  - metadata:\n      name: mysql-data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: \"fast\"\n      resources:\n        requests:\n          storage: 15Gi\n</code></pre></p> Creating a StatefulSet <p>Deploy the StatefulSet using the following command: <pre><code>kubectl apply -f statefulset.yaml\n</code></pre> This command posts the StatefulSet configuration to the Kubernetes API server, which will create and manage the specified Pods and their associated storage.</p> <p>Example output: <pre><code>statefulset.apps/my-sts created\n</code></pre></p> Inspecting StatefulSet and Pods <p>Check the status of the StatefulSet and its Pods: <pre><code>kubectl get sts\n</code></pre> This command displays the status of the StatefulSets in your cluster.</p> <p>Example output: <pre><code>NAME     READY   AGE\nmy-sts   3/3     2m\n</code></pre></p> <p>To get detailed information about the Pods managed by the StatefulSet: <pre><code>kubectl get pods\n</code></pre> This command lists all Pods in your cluster, including those managed by the StatefulSet.</p> <p>Example output: <pre><code>NAME      READY   STATUS    RESTARTS   AGE\nmy-sts-0  1/1     Running   0          2m\nmy-sts-1  1/1     Running   0          1m\nmy-sts-2  1/1     Running   0          30s\n</code></pre></p> Scaling StatefulSets <p>StatefulSets can be scaled up or down, ensuring order and data integrity:</p> <ul> <li>Scaling Up: New Pods are created sequentially.</li> <li>Scaling Down: Pods are deleted in reverse order.</li> </ul> <p>To scale the StatefulSet: <pre><code>kubectl scale sts my-sts --replicas=4\n</code></pre> This command scales the StatefulSet to 4 replicas. Kubernetes will create the new Pod in order, ensuring consistency and stability.</p> <p>Example output: <pre><code>statefulset.apps/my-sts scaled\n</code></pre></p> Handling Failures <p>StatefulSets handle failures by automatically recreating Pods with the same identity and volume bindings:</p> <ul> <li>Pod Failure: A failed Pod is replaced with a new Pod with the same name and volume.</li> <li>Node Failure: Modern Kubernetes versions handle node failures more effectively, replacing Pods on failed nodes automatically.</li> </ul> Using Headless Services <p>StatefulSets often use headless Services to manage network identities:</p> <p>Headless Service YAML: <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mysql-prod\nspec:\n  clusterIP: None\n  selector:\n    app: mysql\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sts-mysql\nspec:\n  serviceName: mysql-prod\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:latest\n        ports:\n        - containerPort: 3306\n</code></pre> The <code>clusterIP: None</code> in the Service configuration creates a headless Service, which means it does not get a ClusterIP address. Instead, it allows Pods to be addressed directly via their DNS names.</p>"},{"location":"statefulsets/#best-practices","title":"Best Practices","text":"<ul> <li>Use Headless Services: Ensure that each Pod gets a stable DNS identity.</li> <li>Monitor Resource Usage: Regularly check the resource utilization of StatefulSets.</li> <li>Backup Persistent Data: Implement backup strategies for data stored in persistent volumes.</li> <li>Consider Network Policies: Use network policies to control traffic to and from StatefulSet Pods.</li> </ul>"},{"location":"statefulsets/#summary","title":"Summary","text":"<p>StatefulSets are crucial for managing stateful applications in Kubernetes. They provide stable network identities, persistent storage, and ordered Pod creation and deletion. By leveraging StatefulSets, you can ensure your stateful applications are robust, scalable, and resilient.</p>"},{"location":"storage/","title":"Mastering Kubernetes Storage","text":"<p>Storing and retrieving data is crucial for most real-world applications. Kubernetes' persistent volume subsystem allows you to connect to enterprise-grade storage systems that provide advanced data management services such as backup and recovery, replication, and snapshots.</p>"},{"location":"storage/#overview","title":"Overview","text":"<p>Kubernetes supports a variety of storage systems, including those from major cloud providers and enterprise-class solutions like EMC and NetApp. This section will cover:</p> <ul> <li>The big picture of Kubernetes storage</li> <li>Various storage providers</li> <li>The Container Storage Interface (CSI)</li> <li>Kubernetes persistent volume subsystem</li> <li>Dynamic provisioning with Storage Classes</li> <li>Hands-on examples</li> </ul>"},{"location":"storage/#the-big-picture","title":"The Big Picture","text":"<p>Kubernetes supports different types of storage, such as block, file, and object storage, from various external systems, either in the cloud or on-premises.</p> Types of Storage <ul> <li>Block Storage: Provides raw storage volumes that can be mounted as disks to Pods. Ideal for databases and applications requiring high-performance storage.</li> <li>File Storage: Offers a shared file system that can be mounted by multiple Pods. Suitable for shared data and configuration files.</li> <li>Object Storage: Stores data as objects, often used for unstructured data like media files and backups.</li> </ul> High-Level Architecture <p>Storage providers connect to Kubernetes through a plugin layer, often using the Container Storage Interface (CSI). This standardized interface simplifies integrating external storage resources with Kubernetes.</p> Key Components <ul> <li>Storage Providers: External systems providing storage services, like EMC, NetApp, or cloud providers.</li> <li>Plugin Layer: Connects external storage systems with Kubernetes, typically using CSI plugins.</li> <li>Kubernetes Persistent Volume Subsystem: Standardized API objects that allow applications to consume storage easily.</li> </ul>"},{"location":"storage/#storage-providers","title":"Storage Providers","text":"<p>Kubernetes supports a wide range of external storage systems, each typically providing its own CSI plugin. These plugins are usually installed via Helm charts or YAML installers and run as Pods in the <code>kube-system</code> Namespace.</p> Restrictions <ul> <li>Cloud-Specific: You can't provision and mount GCP volumes if your cluster is on Microsoft Azure.</li> <li>Locality: Pods often need to be in the same region or zone as the storage backend.</li> </ul>"},{"location":"storage/#container-storage-interface-csi","title":"Container Storage Interface (CSI)","text":"<p>The Container Storage Interface (CSI) is a standard for exposing arbitrary block and file storage systems to containerized workloads on Container Orchestration Systems (COS) like Kubernetes. CSI allows for the consistent configuration and management of storage solutions across various container orchestration systems.</p> Benefits of CSI <ul> <li>Standardization: Provides a consistent interface for storage providers, simplifying integration.</li> <li>Flexibility: Supports a wide range of storage solutions and configurations.</li> <li>Scalability: Enables dynamic provisioning and management of storage resources.</li> <li>Decoupled Updates: CSI plugins can be updated independently of Kubernetes releases.</li> <li>Broad Compatibility: CSI plugins work across different orchestration platforms.</li> </ul> Installing CSI Plugins <p>Most cloud platforms pre-install CSI plugins for native storage services. Third-party storage systems require manual installation, often available as Helm charts or YAML files.</p>"},{"location":"storage/#persistent-volumes-and-claims","title":"Persistent Volumes and Claims","text":"<p>Persistent Volumes (PVs) and Persistent Volume Claims (PVCs) are integral to Kubernetes' storage system, providing a way to manage and consume storage resources.</p> Persistent Volumes (PVs) <p>PVs are cluster-wide storage resources that are provisioned either statically by an administrator or dynamically using Storage Classes. They represent a piece of storage that has been provisioned by an administrator or dynamically created by Kubernetes.</p> <ul> <li>Static Provisioning: Administrators manually create PVs, defining the storage details and capabilities.</li> <li>Dynamic Provisioning: Kubernetes automatically provisions storage based on the Storage Class specified in the PVC.</li> </ul> Persistent Volume Claims (PVCs) <p>PVCs are requests for storage by users. They consume PV resources and specify the desired storage size and access modes (e.g., ReadWriteOnce, ReadOnlyMany, ReadWriteMany).</p> <ul> <li>Binding Process: When a PVC is created, Kubernetes matches it to an available PV based on size and access mode.</li> <li>Lifecycle Management: PVCs allow users to request storage resources without knowing the underlying infrastructure details.</li> </ul> Example YAML for PV and PVC <p>Persistent Volume (PV):</p> <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: standard\n  hostPath:\n    path: \"/mnt/data\"\n</code></pre> <p>Persistent Volume Claim (PVC):</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n  storageClassName: standard\n</code></pre>"},{"location":"storage/#kubernetes-persistent-volume-subsystem","title":"Kubernetes Persistent Volume Subsystem","text":"<p>The Persistent Volume Subsystem in Kubernetes abstracts the underlying storage details, providing a consistent API for users to request and consume storage resources.</p> Key Features <ul> <li>Abstraction: Decouples storage from Pods, allowing for flexible storage management.</li> <li>Reclaim Policies: Defines what happens to a PV when it is released by a PVC (e.g., Retain, Recycle, Delete).</li> <li>Access Modes: Specifies how the volume can be mounted by Pods (e.g., ReadWriteOnce, ReadOnlyMany, ReadWriteMany).</li> </ul> Dynamic Provisioning with Storage Classes <p>Storage Classes provide a way to define different classes of storage, enabling dynamic provisioning of storage resources based on predefined parameters.</p> <ul> <li>Provisioners: Specify the type of storage backend (e.g., aws-ebs, gce-pd).</li> <li>Parameters: Define specific configurations for the storage backend (e.g., volume type, IOPS).</li> </ul> Example YAML for Storage Class <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standard\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp2\n</code></pre>"},{"location":"storage/#best-practices","title":"Best Practices","text":"<ul> <li>Choose the Right Storage Type: Select block, file, or object storage based on application needs.</li> <li>Use Storage Classes: Leverage dynamic provisioning to simplify storage management.</li> <li>Monitor Storage Usage: Regularly check storage utilization and adjust resources as needed.</li> <li>Backup and Recovery: Implement backup strategies to protect data and ensure recovery.</li> </ul>"},{"location":"storage/#example","title":"Example","text":"<p>Example YAML: Below is the high-level flow for creating and using StorageClasses:</p> <ol> <li>Ensure you have a storage back-end (cloud, on-prem, etc.)</li> <li>Have a running Kubernetes cluster</li> <li>Install and setup the CSI storage plugin to connect to Kubernetes</li> <li>Create at least one StorageClass on Kubernetes</li> <li>Deploy Pods with PVCs that reference those Storage classes</li> </ol> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: mypod\nspec:\n  volumes:\n    - name: data\n      persistentVolumeClaim:\n        claimName: mypvc\n  containers:\n  - name: my-container\n    image: myimage\n    volumeMounts:\n    - name: data\n      mountPath: /data\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mypvc\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: fast\n---\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: fast\nprovisioner: pd.csi.storage.gke.io\nparameters:\n  type: pd-ssd\n</code></pre>"},{"location":"storage/#additional-volume-settings","title":"Additional Volume Settings","text":"Access Modes <ul> <li>ReadWriteOnce (RWO): Single PVC can bind to a volume in read-write mode.</li> <li>ReadWriteMany (RWM): Multiple PVCs can bind to a volume in read-write mode.</li> <li>ReadOnlyMany (ROM): Multiple PVCs can bind to a volume in read-only mode.</li> </ul> Reclaim Policy <ul> <li>Delete: Deletes PV and external storage when PVC is released.</li> <li>Retain: Keeps PV and external storage when PVC is deleted, requiring manual cleanup.</li> </ul>"},{"location":"storage/#summary","title":"Summary","text":"<p>Kubernetes provides a robust storage subsystem that allows applications to dynamically provision and manage storage from various external systems. By leveraging CSI plugins and StorageClasses, you can create flexible and scalable storage solutions tailored to your application's needs.</p>"},{"location":"troubleshooting/","title":"Troubleshooting Kubernetes","text":"<p>Troubleshooting is a crucial skill for managing Kubernetes clusters. This section provides strategies and tools for diagnosing and resolving common issues.</p>"},{"location":"troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"Issue Description Solution CrashLoopBackOff Pod repeatedly crashing. Check logs with <code>kubectl logs &lt;pod-name&gt;</code>. ImagePullBackOff Kubernetes cannot pull the container image. Verify the image name and credentials. Node Not Ready Node is not functioning correctly. Check node status with <code>kubectl get nodes</code> and review the kubelet logs. Disk Pressure Node runs low on disk space. Free up space or add more storage. Service Not Accessible Service configuration or endpoints issue. Check service configuration with <code>kubectl get svc</code> and <code>kubectl describe svc &lt;service-name&gt;</code>. DNS Resolution Failures DNS pod status or configuration issue. Verify DNS pod status and configuration with <code>kubectl get pods -n kube-system</code>. Pod Eviction Pods are evicted due to resource constraints. Check node resource usage and adjust limits or requests. High CPU Usage Pods or nodes experiencing high CPU usage. Analyze CPU usage with <code>kubectl top</code> and optimize application resource requests. Network Latency High latency in network communication between Pods. Check network policies and configurations, and ensure sufficient bandwidth."},{"location":"troubleshooting/#tools-for-troubleshooting","title":"Tools for Troubleshooting","text":"Command Description Example Usage <code>describe</code> Provides detailed information about resources. <code>kubectl describe pod &lt;pod-name&gt;</code> <code>logs</code> Retrieves logs from containers. <code>kubectl logs &lt;pod-name&gt;</code> <code>exec</code> Executes commands in a container. <code>kubectl exec -it &lt;pod-name&gt; -- /bin/sh</code> Monitoring and Logging <ul> <li>Prometheus: Collects metrics and provides alerts. It's highly customizable and integrates well with Kubernetes. Learn more</li> <li>Grafana: Visualizes metrics collected by Prometheus and other sources. It offers a rich set of dashboards and visualization tools. Learn more</li> <li>Elasticsearch, Fluentd, Kibana (EFK) Stack: Centralizes logging and provides search capabilities. Elasticsearch stores logs, Fluentd collects and forwards them, and Kibana visualizes the data. Learn more about Elasticsearch, Fluentd, Kibana</li> </ul>"},{"location":"troubleshooting/#best-practices","title":"Best Practices","text":"<ul> <li>Regular Monitoring: Continuously monitor cluster health and performance.</li> <li>Automated Alerts: Set up alerts for critical issues to ensure timely response.</li> <li>Documentation: Keep detailed records of issues and solutions for future reference.</li> </ul>"}]}