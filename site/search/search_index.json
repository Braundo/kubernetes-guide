{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"","text":"<p>Welcome to the Kubernetes Guide, a quick and easy-to-digest summary of core Kubernetes concepts intended to help get you from zero to proficient!</p> <p>One thing to note about text formatting in this guide: you'll notice some terms always start with a capital letter (i.e. Service, Pod, etc.). This is intentional and an attempt to adhere to standard formatting as laid out in the official Kubernetes documentation. Kubernetes API objects (like the ones just mentioned) should start with a capital letter.</p> <p>Legal disclaimer:  \"Kubernetes\", \"K8s\", and the Kubernetes logo are trademarks or registered trademarks of the Linux Foundation.  Neither myself nor this site are officially associated with the Linux Foundation.</p> <p> Connect with me  Suggest changes</p>"},{"location":"about/","title":"About","text":"<p>My name is Aaron Braundmeier and I've been working in the tech industry for over a decade at companies such as Mastercard, VMware, Broadcom and CVS. I've long been a Kubernetes fan and had the privilege of working hands-on in that space during my time within the Tanzu business unit at VMware. Please note that all opinions and content on this site belong to me and do not reflect the opinions, plans, or designs of any of my current or former employers.</p> <p></p> <p>I'm currently working on attaining Kubestronaut status:</p> <ul> <li> Certified Kubernetes Administrator (CKA)</li> <li> Kubernetes Certified Security Associate (KCSA)</li> <li> Kubernetes and Cloud Native Associate (KCNA)</li> <li> Certified Kubernetes Security Specialist (CKS)</li> <li> Certified Kubernetes Application Developer (CKAD)</li> </ul> <p> If you're interested in connecting, I can be reached in the following ways:</p> <p> aaron@braundmeier.com</p> <p> LinkedIn</p> <p> Signal</p> <p></p> Certified Kubernetes Administrator Issuer: The Linux Foundation Kubernetes and Cloud Security Associate Issuer: The Linux Foundation Kubernetes and Cloud Native Associate Issuer: The Linux Foundation Certified Argo Project Associate Issuer: The Linux Foundation"},{"location":"audit-logging/","title":"Audit & Logging","text":"<p>In Kubernetes, audit logging and centralized log collection are critical components of a secure and observable platform. Audit logs help detect policy violations or suspicious behavior, while application and cluster logs help with troubleshooting, monitoring, and forensics.</p>"},{"location":"audit-logging/#audit-logs-in-kubernetes","title":"Audit Logs in Kubernetes","text":"<p>Kubernetes audit logs record the who, what, when, and where of every request made to the Kubernetes API server. These logs are essential for security analysis, compliance, and intrusion detection.</p> <p>Audit logging must be configured explicitly and is typically enabled on the control plane node(s).</p>"},{"location":"audit-logging/#key-fields-in-audit-events","title":"Key Fields in Audit Events","text":"<p>Each audit log entry includes:</p> <ul> <li><code>user.username</code>: Who initiated the request</li> <li><code>verb</code>: What operation was attempted (e.g. <code>create</code>, <code>get</code>, <code>patch</code>)</li> <li><code>objectRef</code>: Which resource was affected</li> <li><code>responseStatus</code>: Whether it succeeded or failed</li> <li><code>stage</code>: The phase of request processing (e.g. <code>RequestReceived</code>, <code>ResponseComplete</code>)</li> </ul>"},{"location":"audit-logging/#example-json-entry-simplified","title":"Example JSON Entry (Simplified)","text":"<pre><code>{\n  \"kind\": \"Event\",\n  \"apiVersion\": \"audit.k8s.io/v1\",\n  \"user\": {\n    \"username\": \"admin\"\n  },\n  \"verb\": \"create\",\n  \"objectRef\": {\n    \"resource\": \"pods\",\n    \"namespace\": \"default\",\n    \"name\": \"nginx\"\n  },\n  \"responseStatus\": {\n    \"code\": 201\n  },\n  \"stage\": \"ResponseComplete\"\n}\n</code></pre>"},{"location":"audit-logging/#enabling-audit-logging","title":"Enabling Audit Logging","text":"<p>Audit logging is configured via the <code>--audit-policy-file</code> and <code>--audit-log-path</code> flags on the API server.</p>"},{"location":"audit-logging/#example-startup-flags","title":"Example startup flags:","text":"<pre><code>--audit-policy-file=/etc/kubernetes/audit-policy.yaml\n--audit-log-path=/var/log/kubernetes/audit.log\n</code></pre> <p>You also define a policy file to control which events get logged:</p> <pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  - level: Metadata\n    verbs: [\"create\", \"delete\"]\n    resources:\n      - group: \"\"\n        resources: [\"pods\"]\n</code></pre>"},{"location":"audit-logging/#centralized-logging-stack","title":"Centralized Logging Stack","text":"<p>To collect and analyze logs from applications, control plane components, and nodes, you\u2019ll typically deploy a logging stack.</p>"},{"location":"audit-logging/#common-choices","title":"Common Choices:","text":"Tool Purpose Fluent Bit Lightweight log forwarder (agent) Fluentd Full-featured log collector/transformer Loki Scalable log store optimized for Kubernetes Elasticsearch Popular full-text search engine Kibana / Grafana Visualization dashboards <p>These tools collect logs from container stdout/stderr or files (e.g., <code>/var/log/containers/</code>) and ship them to a centralized location.</p>"},{"location":"audit-logging/#recommended-architecture","title":"Recommended Architecture","text":"<p>A typical Kubernetes logging pipeline:</p> <pre><code>Pods/Containers\n     \u2193\nFluent Bit / Fluentd (DaemonSet)\n     \u2193\nLoki / Elasticsearch / Custom Sink\n     \u2193\nGrafana / Kibana / Alerting Tools\n</code></pre> <p>This allows: - Full-text search over logs - Filtering by label, container, namespace, or timestamp - Long-term storage for audit/compliance - Alerts on suspicious activity</p>"},{"location":"audit-logging/#best-practices","title":"Best Practices","text":"<ul> <li>Rotate and retain audit logs securely (e.g., via logrotate or cloud log sinks)</li> <li>Don\u2019t log full request/response bodies unless necessary</li> <li>Separate audit logs from normal logs in storage and access control</li> <li>Use RBAC to restrict access to sensitive audit and control plane logs</li> <li>Encrypt logs in transit and at rest if stored outside the cluster</li> </ul>"},{"location":"audit-logging/#summary","title":"Summary","text":"<p>Audit logging and centralized logging are essential for both security and observability in Kubernetes. Audit logs capture cluster-level events for compliance and threat detection, while the logging stack enables real-time visibility and operational insights. Both should be included in any production-grade Kubernetes deployment.</p>"},{"location":"certification-preparation/","title":"Kubernetes Certification Preparation","text":"<p>The CNCF offers several certifications to validate your Kubernetes knowledge. This section helps you prepare for the three core exams:</p> <ul> <li>Certified Kubernetes Administrator (CKA)</li> <li>Certified Kubernetes Application Developer (CKAD)</li> <li>Certified Kubernetes Security Specialist (CKS)</li> </ul> <p>Each guide includes: - Core topics you need to master - Trusted resources and courses - Practical exam tips and environment setup</p>"},{"location":"certification-preparation/#exam-overview","title":"Exam Overview","text":"Cert Duration Format Focus Area CKA 2 hours Hands-on lab Cluster operations, admin CKAD 2 hours Hands-on lab App design, deployment CKS 2 hours Hands-on lab Security and hardening"},{"location":"certification-preparation/#general-advice","title":"General Advice","text":"<ul> <li>Practice in a real cluster \u2014 don\u2019t rely only on theory</li> <li>Learn to navigate <code>kubectl</code> quickly \u2014 alias everything</li> <li>Master <code>vim</code>, <code>tmux</code>, and <code>kubectl explain</code></li> <li>Use tab-complete and <code>kubectl -h</code> constantly</li> <li>Use <code>--dry-run=client -o yaml</code> for rapid manifest generation</li> </ul>"},{"location":"certification-preparation/#resources","title":"Resources","text":""},{"location":"certification-preparation/#books","title":"Books","text":"Book Title Link Kubernetes Up &amp; Running Kubernetes Up &amp; Running The Kubernetes Book The Kubernetes Book Certified Kubernetes Administrator Study Guide Certified Kubernetes Administrator Study Guide Quick Start Kubernetes Quick Start Kubernetes Networking &amp; Kubernetes Networking &amp; Kubernetes Kubernetes Best Practices Kubernetes Best Practices The Book of Kubernetes The Book of Kubernetes"},{"location":"certification-preparation/#documentation","title":"Documentation","text":"Description Link Official Kubernetes documentation. Kubernetes Documentation"},{"location":"certification-preparation/#online-courses","title":"Online Courses","text":"Course Link CKA Course on Udemy CKA Course on Udemy CKAD Design &amp; Build on Pluralsight CKAD Design &amp; Build on Pluralsight"},{"location":"certification-preparation/#practice-labs","title":"Practice Labs","text":"Description Link Katacoda Katacoda Play with Kubernetes Play with Kubernetes Killer Shell killer.sh <p>Note: You\u2019ll have access to kubernetes.io/docs and github.com/kubernetes during the exam.</p>"},{"location":"certification-preparation/#ready-to-dive-in","title":"Ready to Dive In?","text":"<p>Choose your path:</p> <ul> <li>\ud83d\udc49 CKA \u2013 Admin-focused</li> <li>\ud83d\udc49 CKAD \u2013 Developer-focused</li> <li>\ud83d\udc49 CKS \u2013 Security-focused</li> </ul>"},{"location":"cka/","title":"Certified Kubernetes Administrator (CKA)","text":"<p>The Certified Kubernetes Administrator (CKA) exam tests your ability to install, configure, and manage Kubernetes clusters in real-world scenarios. It focuses heavily on system-level operations, cluster components, and day-to-day administrator tasks.</p>"},{"location":"cka/#exam-overview","title":"\ud83e\udde0 Exam Overview","text":"<ul> <li>Format: Hands-on, performance-based lab</li> <li>Duration: 2 hours</li> <li>Passing score: 66%</li> <li>Price: $395 USD (includes one retake)</li> <li>Open book: Access to kubernetes.io/docs and GitHub</li> </ul>"},{"location":"cka/#domains-weights","title":"\ud83d\udccb Domains &amp; Weights","text":"Domain Weight Cluster Architecture, Installation &amp; Configuration 25% Workloads &amp; Scheduling 15% Services &amp; Networking 20% Storage 10% Troubleshooting 30%"},{"location":"cka/#what-you-should-master","title":"\u2705 What You Should Master","text":""},{"location":"cka/#1-cluster-architecture-setup-25","title":"1. Cluster Architecture &amp; Setup (25%)","text":"<ul> <li><code>kubeadm init</code>, <code>join</code>, <code>reset</code></li> <li>Control plane components: API server, scheduler, controller manager</li> <li>Node components: kubelet, kube-proxy, container runtime</li> <li><code>kubectl config</code> + kubeconfig structure</li> <li>Certificate management (CA, client certs)</li> <li><code>etcdctl</code> backup and restore</li> <li>Static Pods and manifests in <code>/etc/kubernetes/manifests</code></li> <li>Taints and tolerations</li> </ul>"},{"location":"cka/#2-workloads-scheduling-15","title":"2. Workloads &amp; Scheduling (15%)","text":"<ul> <li>Deployments, ReplicaSets, Jobs, CronJobs</li> <li>Labels, selectors, and affinity/anti-affinity rules</li> <li>Taints, tolerations, and node selectors</li> <li>DaemonSets</li> </ul>"},{"location":"cka/#3-services-networking-20","title":"3. Services &amp; Networking (20%)","text":"<ul> <li>ClusterIP, NodePort, LoadBalancer</li> <li>CoreDNS troubleshooting</li> <li>NetworkPolicies (basic understanding)</li> <li>Ingress (YAML-level familiarity)</li> <li>Pod-to-Pod communication</li> </ul>"},{"location":"cka/#4-storage-10","title":"4. Storage (10%)","text":"<ul> <li>Volumes and volumeMounts</li> <li>PersistentVolumes (PV) and PersistentVolumeClaims (PVC)</li> <li>StorageClasses</li> <li>AccessModes and reclaim policies</li> </ul>"},{"location":"cka/#5-troubleshooting-30","title":"5. Troubleshooting (30%)","text":"<ul> <li>Pod/container status (<code>kubectl describe</code>, logs, events)</li> <li><code>kubectl exec</code>, <code>port-forward</code></li> <li>CrashLoopBackOff, ImagePullBackOff</li> <li>Control plane failure detection (kubelet, etcd, API server)</li> <li>Networking and DNS issues</li> <li>Resource scheduling issues (taints, affinity, nodeSelector)</li> <li>CNI problems</li> </ul>"},{"location":"cka/#practice-tips","title":"\u2699\ufe0f Practice Tips","text":"<ul> <li>Set up a local cluster using <code>kubeadm</code> (or use labs like Killer.sh)</li> <li>Use <code>kubectl explain</code> often to understand object structure</li> <li>Use <code>kubectl -n kube-system get pods</code> to monitor system health</li> <li>Alias these commands:</li> </ul> <pre><code>alias k=kubectl\nalias kgp='kubectl get pods'\nalias kaf='kubectl apply -f'\n</code></pre> <ul> <li>Practice writing manifests quickly with:</li> </ul> <pre><code>kubectl run nginx --image=nginx --dry-run=client -o yaml\n</code></pre> <ul> <li>Use <code>kubectl edit</code> and <code>kubectl patch</code> to modify resources live</li> </ul>"},{"location":"cka/#test-environment-tips","title":"\ud83e\uddea Test Environment Tips","text":"<ul> <li>Open multiple terminal tabs (one for docs, one for kubectl)</li> <li>Bookmark key doc pages:</li> <li>Install tools</li> <li>Tasks \u2192 Configure Pods</li> <li>Reference</li> <li>Use <code>/etc/kubernetes/manifests/</code> for static Pod edits</li> <li>Save <code>etcd</code> backup and restore syntax</li> </ul>"},{"location":"cka/#recommended-resources","title":"\ud83d\udcda Recommended Resources","text":"<ul> <li>Kubernetes Official Docs</li> <li>Killer.sh Simulator (free with CKA)</li> <li>KodeKloud CKA Course</li> <li>Linux Foundation CKA Training</li> <li>YouTube: TechWorld with Nana \u2013 CKA Series</li> </ul>"},{"location":"cka/#summary","title":"Summary","text":"<p>The CKA exam simulates real-world cluster admin tasks. You\u2019ll be troubleshooting, configuring, deploying, and debugging in a live cluster. With good YAML speed and familiarity with <code>kubectl</code>, you\u2019ll be ready to pass with confidence.</p> <p>Start with the fundamentals. Practice under time pressure. Know where to look in the docs.</p>"},{"location":"ckad/","title":"Certified Kubernetes Application Developer (CKAD)","text":"<p>The CKAD certification tests your ability to design, build, and run applications in Kubernetes. It's focused on real-world usage of Kubernetes primitives \u2014 deployments, configs, probes, volumes, and services \u2014 from a developer's perspective.</p>"},{"location":"ckad/#exam-overview","title":"\ud83e\udde0 Exam Overview","text":"<ul> <li>Format: Hands-on, browser-based lab</li> <li>Duration: 2 hours</li> <li>Passing score: 66%</li> <li>Price: $395 USD (includes one retake)</li> <li>Open book: Access to kubernetes.io/docs</li> </ul>"},{"location":"ckad/#domains-weights","title":"\ud83d\udccb Domains &amp; Weights","text":"Domain Weight Core Concepts 13% Configuration 18% Multi-Container Pods 10% Observability 18% Pod Design 20% Services &amp; Networking 13% State Persistence 8%"},{"location":"ckad/#what-you-should-master","title":"\u2705 What You Should Master","text":""},{"location":"ckad/#1-core-concepts-13","title":"1. Core Concepts (13%)","text":"<ul> <li>Pod lifecycle and restart policies</li> <li>YAML basics: <code>kind</code>, <code>metadata</code>, <code>spec</code></li> <li><code>kubectl explain</code>, <code>run</code>, <code>logs</code>, <code>exec</code></li> </ul>"},{"location":"ckad/#2-configuration-18","title":"2. Configuration (18%)","text":"<ul> <li>ConfigMaps &amp; Secrets (env and volumes)</li> <li><code>env</code>, <code>envFrom</code>, <code>valueFrom</code></li> <li>Probes: liveness, readiness, startup</li> <li>Resource <code>requests</code> and <code>limits</code></li> <li><code>initContainers</code></li> </ul>"},{"location":"ckad/#3-pod-design-20","title":"3. Pod Design (20%)","text":"<ul> <li>Deployments, ReplicaSets, Jobs, CronJobs</li> <li>Multi-container Pods (sidecar pattern)</li> <li>Labels &amp; selectors</li> <li>Rolling updates &amp; rollbacks</li> </ul>"},{"location":"ckad/#4-multi-container-pods-10","title":"4. Multi-Container Pods (10%)","text":"<ul> <li>Sharing volumes, network namespace</li> <li>Common patterns:</li> <li>Sidecar (logging, proxy)</li> <li>Adapter (log converter, translator)</li> <li>Ambassador (external traffic entrypoint)</li> </ul>"},{"location":"ckad/#5-observability-18","title":"5. Observability (18%)","text":"<ul> <li><code>kubectl logs</code>, <code>describe</code>, <code>top</code></li> <li>Events and debugging Pods</li> <li>Container exit codes and status</li> <li>Custom probes for health checks</li> <li>Monitoring concepts (but not setup)</li> </ul>"},{"location":"ckad/#6-services-networking-13","title":"6. Services &amp; Networking (13%)","text":"<ul> <li>ClusterIP, NodePort (no LoadBalancer config needed)</li> <li>Headless Services</li> <li>DNS-based Pod discovery</li> <li>Understanding service selectors</li> </ul>"},{"location":"ckad/#7-state-persistence-8","title":"7. State Persistence (8%)","text":"<ul> <li>Volumes and volumeMounts</li> <li>PersistentVolumeClaims (PVCs)</li> <li>AccessModes: <code>ReadWriteOnce</code>, <code>ReadOnlyMany</code></li> <li>EmptyDir (for temporary scratch space)</li> </ul>"},{"location":"ckad/#practice-tips","title":"\u2699\ufe0f Practice Tips","text":"<ul> <li>Alias often-used commands:</li> </ul> <pre><code>alias k=kubectl\nalias kgp='kubectl get pods'\nalias kaf='kubectl apply -f'\n</code></pre> <ul> <li>Use dry-run + output:</li> </ul> <pre><code>kubectl run nginx --image=nginx --dry-run=client -o yaml\n</code></pre> <ul> <li>Practice common configs:</li> <li>YAML for Pods with ConfigMap/Secret env vars</li> <li>Liveness and readiness probes</li> <li>Multi-container Pod with shared volume</li> </ul>"},{"location":"ckad/#test-environment-tips","title":"\ud83e\uddea Test Environment Tips","text":"<ul> <li>Open docs in one tab, terminal in another</li> <li>Bookmark these:</li> <li>Tasks</li> <li>kubectl Cheat Sheet</li> <li>Workloads Overview</li> <li>Use <code>kubectl explain</code> to recall spec fields quickly</li> <li>Copy/paste manifest scaffolds from the docs to save time</li> </ul>"},{"location":"ckad/#recommended-resources","title":"\ud83d\udcda Recommended Resources","text":"<ul> <li>Kubernetes Official Docs</li> <li>Killer.sh Simulator</li> <li>KodeKloud CKAD Course</li> <li>Linux Foundation CKAD Training</li> <li>YouTube: TechWorld with Nana \u2013 CKAD Series</li> </ul>"},{"location":"ckad/#summary","title":"Summary","text":"<p>The CKAD exam tests your Kubernetes fluency as a developer. You\u2019ll create and configure Pods, manage configs and secrets, debug issues, and expose applications.</p> <p>If you\u2019re confident writing manifests and using <code>kubectl</code> with speed, you\u2019re ready to pass.</p>"},{"location":"cks/","title":"Certified Kubernetes Security Specialist (CKS)","text":"<p>The CKS certification tests your ability to secure Kubernetes clusters and workloads. It\u2019s hands-on, intense, and assumes you already understand Kubernetes deeply (CKA is a prerequisite).</p>"},{"location":"cks/#exam-overview","title":"\ud83e\udde0 Exam Overview","text":"<ul> <li>Format: Hands-on lab with scenarios</li> <li>Duration: 2 hours</li> <li>Passing score: 67%</li> <li>Prerequisite: Active CKA certification</li> <li>Open book: Access to kubernetes.io + GitHub repos</li> </ul>"},{"location":"cks/#domains-weights","title":"\ud83d\udccb Domains &amp; Weights","text":"Domain Weight Cluster Setup 10% System Hardening 15% Minimize Microservice Vulnerabilities 20% Supply Chain Security 20% Monitoring, Logging &amp; Runtime Security 25% RBAC &amp; Network Policies 10%"},{"location":"cks/#what-you-should-master","title":"\u2705 What You Should Master","text":""},{"location":"cks/#1-cluster-setup-10","title":"1. Cluster Setup (10%)","text":"<ul> <li>TLS certificates &amp; CA bundles</li> <li>Encrypt secrets at rest (KMS + <code>EncryptionConfiguration</code>)</li> <li>Audit policy config and log location</li> <li>API server flags: <code>--audit-log-path</code>, <code>--enable-admission-plugins</code></li> </ul>"},{"location":"cks/#2-system-hardening-15","title":"2. System Hardening (15%)","text":"<ul> <li>Restrict host access: block <code>hostPath</code>, <code>hostNetwork</code>, <code>privileged</code></li> <li>Use <code>securityContext</code>:</li> <li><code>runAsNonRoot</code>, <code>readOnlyRootFilesystem</code>, <code>allowPrivilegeEscalation: false</code></li> <li>Restrict capabilities (<code>capabilities.drop: [\"ALL\"]</code>)</li> <li>Pod Security Admission (PSA) with restricted profile</li> <li>Runtime namespace protections (AppArmor / seccomp)</li> </ul>"},{"location":"cks/#3-minimize-microservice-vulnerabilities-20","title":"3. Minimize Microservice Vulnerabilities (20%)","text":"<ul> <li>Scan images with Trivy, Grype, or Dockle</li> <li>Sign images with cosign and verify before deployment</li> <li>Use scratch/minimal base images</li> <li>Avoid running as root in Dockerfiles</li> <li>Validate liveness/readiness probe security</li> </ul>"},{"location":"cks/#4-supply-chain-security-20","title":"4. Supply Chain Security (20%)","text":"<ul> <li>Use trusted registries and signed images</li> <li>Scan YAML manifests for insecure configurations (e.g., <code>kubesec</code>, <code>kube-score</code>)</li> <li>Admission control:</li> <li>Validating/mutating webhooks</li> <li>Gatekeeper/OPA policies</li> <li>ImagePullPolicy: <code>Always</code></li> </ul>"},{"location":"cks/#5-monitoring-logging-runtime-security-25","title":"5. Monitoring, Logging &amp; Runtime Security (25%)","text":"<ul> <li>Audit policy and log filtering</li> <li>Tools:</li> <li>Falco (real-time threat detection)</li> <li>Sysdig, AuditD, or <code>ausearch</code></li> <li>Monitor execs, privilege escalation, network anomalies</li> <li>Understand and tune Falco rules</li> </ul>"},{"location":"cks/#6-rbac-network-policies-10","title":"6. RBAC &amp; Network Policies (10%)","text":"<ul> <li>Create <code>Role</code>, <code>ClusterRole</code>, <code>RoleBinding</code>, <code>ClusterRoleBinding</code></li> <li>Apply <code>NetworkPolicy</code> to restrict Pod traffic (ingress/egress)</li> <li>Avoid <code>*</code> verbs and <code>*</code> resources in RBAC</li> <li>Restrict access by namespace and API group</li> </ul>"},{"location":"cks/#practice-tips","title":"\u2699\ufe0f Practice Tips","text":"<ul> <li>Practice scanning + signing images:</li> <li><code>trivy image nginx:latest</code></li> <li><code>cosign sign --key cosign.key myrepo/app:1.0</code></li> <li>Create test policies for:</li> <li>PSA</li> <li>RBAC + <code>kubectl auth can-i</code></li> <li>NetworkPolicy deny-by-default rules</li> <li>Trigger and detect audit events</li> <li>Write Falco rules for suspicious behaviors</li> </ul>"},{"location":"cks/#test-environment-tips","title":"\ud83e\uddea Test Environment Tips","text":"<ul> <li>Use bookmarks:</li> <li>Pod Security Standards</li> <li>Audit Logging</li> <li>Sysdig Falco</li> <li>Open multiple terminals: cluster work, docs lookup, test scripts</li> <li>Save frequently used YAML snippets</li> </ul>"},{"location":"cks/#recommended-resources","title":"\ud83d\udcda Recommended Resources","text":"<ul> <li>Kubernetes Official Docs</li> <li>Killer.sh Simulator (CKS)</li> <li>KodeKloud CKS Course</li> <li>Linux Foundation CKS Training</li> <li>Sysdig Falco + GitHub rules</li> </ul>"},{"location":"cks/#summary","title":"Summary","text":"<p>CKS is all about applying security best practices under pressure. You\u2019ll configure audit logs, write PodSecurity controls, patch RBAC, restrict networks, and scan or sign container images \u2014 all in live clusters.</p> <p>Hands-on practice is key. Read YAML fast. Think like an attacker.</p>"},{"location":"configmaps-secrets/","title":"ConfigMaps &amp; Secrets","text":"<p>Kubernetes lets you decouple application configuration from container images using two key resources:</p> <ul> <li>ConfigMaps for non-sensitive data (settings, URLs, etc.)</li> <li>Secrets for sensitive data (passwords, tokens, certificates)</li> </ul> <p>These resources allow you to define environment-specific values once and reuse them across multiple workloads \u2014 improving security, consistency, and portability.</p>"},{"location":"configmaps-secrets/#configmaps-non-sensitive-configuration","title":"ConfigMaps (Non-Sensitive Configuration)","text":"<p>A ConfigMap is a key-value store for plain-text configuration. Use it for:</p> <ul> <li>Environment-specific settings (<code>LOG_LEVEL</code>, <code>API_BASE_URL</code>)</li> <li>Hostnames, ports, feature flags</li> <li>Complete config files or CLI arguments</li> </ul>"},{"location":"configmaps-secrets/#example","title":"Example","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  LOG_LEVEL: debug\n  DB_HOST: db.default.svc.cluster.local\n</code></pre>"},{"location":"configmaps-secrets/#secrets-sensitive-data","title":"Secrets (Sensitive Data)","text":"<p>Secrets are also key-value stores \u2014 but intended for private data such as:</p> <ul> <li>Passwords, tokens, and API keys</li> <li>SSH keys or TLS certs</li> <li>Docker registry credentials</li> </ul> <p>Kubernetes encodes all Secret values in base64. Note: this is for transport, not security.</p>"},{"location":"configmaps-secrets/#example_1","title":"Example","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\ntype: Opaque\ndata:\n  DB_PASSWORD: c3VwZXJzZWNyZXQ=\n</code></pre> <p>\u24d8 Decode with: <code>echo c3VwZXJzZWNyZXQ= | base64 -d</code> Use <code>stringData:</code> if you want Kubernetes to handle the encoding automatically.</p>"},{"location":"configmaps-secrets/#ways-to-use-configmaps-and-secrets","title":"Ways to Use ConfigMaps and Secrets","text":"<p>There are three main ways to expose values inside your Pods:</p>"},{"location":"configmaps-secrets/#1-environment-variables","title":"1. Environment Variables","text":"<p>Inject all key-value pairs from a ConfigMap or Secret:</p> <pre><code>envFrom:\n  - configMapRef:\n      name: app-config\n  - secretRef:\n      name: db-secret\n</code></pre> <p>Or reference individual keys:</p> <pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: db-secret\n        key: DB_PASSWORD\n</code></pre>"},{"location":"configmaps-secrets/#2-mounted-volumes","title":"2. Mounted Volumes","text":"<p>Map each key to a file inside the container:</p> <pre><code>volumes:\n  - name: config-vol\n    configMap:\n      name: app-config\ncontainers:\n  - name: app\n    volumeMounts:\n      - name: config-vol\n        mountPath: /etc/config\n</code></pre> <p>In the container, this results in:</p> <pre><code>/etc/config/LOG_LEVEL\n/etc/config/DB_HOST\n</code></pre> <p>You can do the same for Secrets:</p> <pre><code>volumes:\n  - name: creds\n    secret:\n      secretName: db-secret\n</code></pre> <p>\u26a0\ufe0f Secrets mounted as files on disk are only base64-decoded. They are not encrypted unless you've enabled encryption at rest.</p>"},{"location":"configmaps-secrets/#3-cli-arguments-or-command-overrides","title":"3. CLI Arguments or Command Overrides","text":"<pre><code>containers:\n  - name: app\n    image: myapp\n    args:\n      - \"--log-level=$(LOG_LEVEL)\"\n    env:\n      - name: LOG_LEVEL\n        valueFrom:\n          configMapKeyRef:\n            name: app-config\n            key: LOG_LEVEL\n</code></pre>"},{"location":"configmaps-secrets/#best-practices","title":"Best Practices","text":"<ul> <li>Use ConfigMaps for plain-text configuration and Secrets for anything private.</li> <li>Use RBAC to control access to Secrets.</li> <li>Enable encryption at rest for Secret resources (<code>EncryptionConfiguration</code>).</li> <li>Avoid committing secrets to Git \u2014 even in base64 form.</li> <li>Use tools like Sealed Secrets, Vault, or external-secrets to integrate with cloud-native secrets managers.</li> </ul>"},{"location":"configmaps-secrets/#summary","title":"Summary","text":"<ul> <li>ConfigMaps store non-sensitive values like app settings and hostnames.</li> <li>Secrets store sensitive data like passwords and certificates \u2014 encoded, but not encrypted by default.</li> <li>Both can be used via environment variables, mounted volumes, or command overrides.</li> <li>Combine with proper RBAC and encryption settings for production use.</li> </ul>"},{"location":"daemonsets/","title":"Managing DaemonSets in Kubernetes","text":"<p>DaemonSets ensure that all (or some) nodes run a copy of a Pod. They are used for deploying system-level applications like log collectors, monitoring agents, and other node-specific services.</p> Introduction to DaemonSets <p>DaemonSets are designed to manage the deployment of Pods across all nodes in a cluster. They ensure that a specific Pod is running on each node, making them ideal for system-level applications.</p> Use Cases for DaemonSets <p>DaemonSets are commonly used for:</p> <ul> <li>Log Collection: Deploying log collection agents on each node.</li> <li>Monitoring: Running monitoring agents to collect metrics from nodes.</li> <li>Networking: Managing network services like DNS or proxy servers.</li> </ul> Key Features <ul> <li>Automatic Updates: Automatically adds Pods to new nodes when they are added to the cluster.</li> <li>Selective Deployment: Can be configured to deploy Pods only to specific nodes using node selectors.</li> <li>Rolling Updates: Supports rolling updates to update Pods without downtime.</li> </ul> Managing DaemonSets <p>DaemonSets can be managed using various Kubernetes features:</p> <ul> <li>Node Selectors: Control which nodes a DaemonSet's Pods are scheduled on.</li> <li>Tolerations: Allow DaemonSet Pods to run on nodes with specific taints.</li> <li>Update Strategy: Configure rolling updates to minimize disruption.</li> </ul> Example YAML for DaemonSet <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\nspec:\n  selector:\n    matchLabels:\n      name: fluentd\n  template:\n    metadata:\n      labels:\n        name: fluentd\n    spec:\n      containers:\n      - name: fluentd\n        image: fluent/fluentd:v1.11\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: 100m\n      tolerations:\n      - key: \"node-role.kubernetes.io/master\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n</code></pre>"},{"location":"daemonsets/#best-practices","title":"Best Practices","text":"<ul> <li>Resource Management: Define resource requests and limits to ensure efficient use of node resources.</li> <li>Node Affinity: Use node affinity to control where Pods are scheduled.</li> <li>Monitor DaemonSet Health: Regularly check the status and health of DaemonSets to ensure they are running as expected.</li> <li>Scaling Considerations: Plan for scaling by understanding the resource requirements of DaemonSet Pods.</li> </ul>"},{"location":"env-var/","title":"Env. Variables & Probes","text":"<p>Kubernetes allows you to configure runtime behavior of containers using environment variables, and to monitor their health using liveness and readiness probes. These features are essential for building reliable, configurable, and observable applications in the cluster.</p>"},{"location":"env-var/#environment-variables","title":"Environment Variables","text":"<p>You can pass key-value pairs into containers using environment variables. These can be hardcoded, referenced from ConfigMaps, Secrets, or even dynamically derived from field references.</p>"},{"location":"env-var/#static-environment-variables","title":"Static Environment Variables","text":"<pre><code>env:\n  - name: LOG_LEVEL\n    value: \"debug\"\n</code></pre>"},{"location":"env-var/#from-configmap","title":"From ConfigMap","text":"<pre><code>envFrom:\n  - configMapRef:\n      name: app-config\n</code></pre> <p>Or individual keys:</p> <pre><code>env:\n  - name: APP_PORT\n    valueFrom:\n      configMapKeyRef:\n        name: app-config\n        key: port\n</code></pre>"},{"location":"env-var/#from-secret","title":"From Secret","text":"<pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: db-secret\n        key: password\n</code></pre>"},{"location":"env-var/#from-pod-metadata","title":"From Pod Metadata","text":"<pre><code>env:\n  - name: POD_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.name\n</code></pre>"},{"location":"env-var/#probes-overview","title":"Probes Overview","text":"<p>Kubernetes uses probes to check if a container is:</p> <ul> <li>Alive (liveness probe): Whether the app should be restarted</li> <li>Ready (readiness probe): Whether the app is ready to receive traffic</li> <li>Started (startup probe): Whether the app has finished starting up</li> </ul> <p>Each probe runs a check (HTTP request, TCP socket, or command) and takes action based on success or failure.</p>"},{"location":"env-var/#liveness-probe","title":"Liveness Probe","text":"<p>Restarts the container if the probe fails repeatedly.</p> <pre><code>livenessProbe:\n  httpGet:\n    path: /healthz\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 10\n</code></pre>"},{"location":"env-var/#readiness-probe","title":"Readiness Probe","text":"<p>Used to signal when the container is ready to receive traffic. If the probe fails, the Pod is removed from Service endpoints.</p> <pre><code>readinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 10\n</code></pre>"},{"location":"env-var/#startup-probe","title":"Startup Probe","text":"<p>Useful for applications that take a long time to initialize. Prevents premature liveness failures during startup.</p> <pre><code>startupProbe:\n  httpGet:\n    path: /startup\n    port: 8080\n  failureThreshold: 30\n  periodSeconds: 10\n</code></pre>"},{"location":"env-var/#best-practices","title":"Best Practices","text":"<ul> <li>Use readiness probes to avoid routing traffic to unready pods.</li> <li>Use liveness probes for self-healing on deadlocks or hung apps.</li> <li>Use startup probes for slow-starting applications.</li> <li>Avoid setting <code>initialDelaySeconds</code> too low \u2014 allow the app to start first.</li> <li>Prefer HTTP or command probes for rich diagnostics.</li> </ul>"},{"location":"env-var/#summary","title":"Summary","text":"<p>Environment variables allow you to make your containerized applications configurable without rebuilding images. Probes give Kubernetes insight into the health and lifecycle of your applications, enabling smart traffic routing and automated restarts. Together, these tools form the backbone of robust and production-ready workloads.</p>"},{"location":"helm-package-management/","title":"Helm","text":"<p>Helm is a powerful tool for managing Kubernetes applications. It simplifies application deployment and management by using packages called \"charts.\" This page will cover an introduction to Helm, its benefits, and how to create and use Helm charts effectively.</p>"},{"location":"helm-package-management/#introduction-to-helm","title":"Introduction to Helm","text":"What is Helm? <p>Helm is a package manager for Kubernetes that allows you to define, install, and upgrade complex Kubernetes applications. It uses a packaging format called charts, which are collections of files that describe a related set of Kubernetes resources.</p> Benefits of Using Helm <p>Helm provides several benefits for managing Kubernetes applications:</p> <ul> <li>Simplifies Deployment: Packages multiple Kubernetes resources into a single unit, making it easier to deploy complex applications.</li> <li>Versioning: Supports versioning of charts, enabling easy upgrades and rollbacks.</li> <li>Reuse: Allows you to reuse charts for different environments, reducing duplication.</li> <li>Customization: Supports customizable templates to adapt to different environments and configurations.</li> <li>Dependency Management: Manages dependencies between different charts.</li> </ul> Helm Architecture <p>Helm operates with two main components:</p> <ol> <li>Helm Client: The command-line tool that you use to create, install, and manage Helm charts.</li> <li>Helm Server (Tiller): In Helm v2, Tiller runs inside the Kubernetes cluster and manages the deployment of charts. Note that Helm v3 has removed Tiller, and the client communicates directly with the Kubernetes API server.</li> </ol> How Helm Works <ul> <li>Charts: Collections of files that describe a related set of Kubernetes resources.</li> <li>Values Files: Used to customize the deployment by overriding default values.</li> <li>Templates: Allow dynamic generation of Kubernetes manifests.</li> <li>Releases: An instance of a chart running in a Kubernetes cluster.</li> <li>Repositories: Collections of charts that can be shared and reused.</li> </ul>"},{"location":"helm-package-management/#creating-and-using-helm-charts","title":"Creating and Using Helm Charts","text":"Creating a Helm Chart <p>To create a new Helm chart, use the following command: <pre><code>$ helm create my-chart\n</code></pre></p> <p>This command generates a directory structure with default files: <pre><code>my-chart/\n  Chart.yaml          # Chart metadata\n  values.yaml         # Default configuration values\n  charts/             # Dependency charts\n  templates/          # Kubernetes resource templates\n</code></pre></p> Example Chart.yaml <pre><code>apiVersion: v2\nname: my-chart\nversion: 0.1.0\ndescription: A Helm chart for Kubernetes\n</code></pre> Advanced Helm Features <ul> <li>Hooks: Allow you to run scripts at specific points in a release lifecycle.</li> <li>Lifecycle Management: Manage the lifecycle of applications with upgrade and rollback capabilities.</li> <li>Managing Dependencies: Use the <code>requirements.yaml</code> file to manage chart dependencies.</li> </ul> Customizing Helm Charts <p>Customize charts for different environments by using values files and templates to override default settings.</p>"},{"location":"helm-package-management/#best-practices","title":"Best Practices","text":"<ul> <li>Version Control: Keep your charts in version control for easy tracking and collaboration.</li> <li>Testing: Test your charts in different environments to ensure compatibility.</li> <li>Security: Regularly update your charts to include the latest security patches.</li> <li>Documentation: Provide clear documentation for using and customizing your charts.</li> </ul>"},{"location":"image-scan-sign/","title":"Image Scanning & Signing","text":"<p>Container images are one of the most common vectors for introducing vulnerabilities into Kubernetes clusters. Malicious, outdated, or misconfigured images can lead to privilege escalation, supply chain attacks, or data breaches. To address this, Kubernetes platforms and DevSecOps workflows rely on image scanning and image signing.</p>"},{"location":"image-scan-sign/#image-scanning","title":"Image Scanning","text":"<p>Image scanning analyzes container images for known vulnerabilities in operating system packages, libraries, and application dependencies.</p>"},{"location":"image-scan-sign/#when-to-scan","title":"When to Scan:","text":"<ul> <li>During CI/CD before pushing to a registry</li> <li>On a schedule, as CVEs are constantly updated</li> <li>Before deployment into production clusters</li> </ul>"},{"location":"image-scan-sign/#common-tools","title":"Common Tools:","text":"Tool Type Key Features Trivy CLI / CI / Kubernetes Lightweight, fast scanner with SBOM support Grype CLI / CI Deep image scanning, good SBOM integration Clair API / Registry Integrates with container registries like Harbor Anchore CI/CD platform Policy-based scanning and reporting Aqua / Prisma / Snyk Enterprise Advanced scanning, RBAC integration, UI dashboards"},{"location":"image-scan-sign/#example-scanning-with-trivy","title":"Example: Scanning with Trivy","text":"<pre><code>trivy image nginx:1.21\n</code></pre> <p>This command checks for CVEs in the <code>nginx:1.21</code> image and provides severity breakdowns and remediation guidance.</p>"},{"location":"image-scan-sign/#image-signing","title":"Image Signing","text":"<p>Image signing ensures the authenticity and integrity of container images. Signed images can be verified before they are pulled or deployed to ensure they haven\u2019t been tampered with.</p> <p>Signing involves: 1. Creating a cryptographic signature for an image 2. Attaching it to the image metadata or registry 3. Verifying the signature during admission or runtime</p>"},{"location":"image-scan-sign/#tools","title":"Tools:","text":"Tool Purpose Notes cosign Signing and verifying OCI images Lightweight and integrates with Sigstore Notary v2 Signing framework (Docker 2.0) Upcoming standard for OCI image signing Sigstore Ecosystem for supply chain trust Powers cosign, keyless signing, policy"},{"location":"image-scan-sign/#example-signing-and-verifying-with-cosign","title":"Example: Signing and Verifying with cosign","text":"<pre><code># Sign the image\ncosign sign ghcr.io/example/image:tag\n\n# Verify the image signature\ncosign verify ghcr.io/example/image:tag\n</code></pre> <p>Cosign supports keyless signing using identity providers like GitHub Actions or OIDC credentials.</p>"},{"location":"image-scan-sign/#enforcing-signed-images","title":"Enforcing Signed Images","text":"<p>Signed images can be enforced at admission time using:</p> <ul> <li>Kyverno: Policy engine that can block unsigned or unverified images</li> <li>OPA Gatekeeper: Rego-based policies for image trust</li> <li>Sigstore Policy Controller: Native support for verifying signatures on admission</li> </ul>"},{"location":"image-scan-sign/#example-kyverno-policy-snippet","title":"Example: Kyverno Policy Snippet","text":"<pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: verify-image-signatures\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: require-signed-images\n    match:\n      resources:\n        kinds:\n        - Pod\n    validate:\n      message: \"Image must be signed with cosign.\"\n      pattern:\n        spec:\n          containers:\n          - image: \"*\"\n            imagePullPolicy: \"Always\"\n</code></pre>"},{"location":"image-scan-sign/#best-practices","title":"Best Practices","text":"<ul> <li>Integrate scanning into CI/CD pipelines to catch issues early</li> <li>Continuously monitor for newly discovered CVEs</li> <li>Use image signing to enforce trusted provenance</li> <li>Regularly rotate signing keys and scan SBOMs (Software Bill of Materials)</li> <li>Avoid <code>:latest</code> tags \u2014 use immutable, versioned image references</li> </ul>"},{"location":"image-scan-sign/#summary","title":"Summary","text":"<p>Scanning and signing container images are critical steps in securing your Kubernetes supply chain. Scanning prevents vulnerable software from being deployed, while signing ensures you're running trusted, unmodified images. Together, they help protect your workloads from tampering and known exploits, forming the foundation of modern Kubernetes security.</p>"},{"location":"init-containers/","title":"Init Containers","text":"<p>Init containers run before regular containers in a Pod start. They\u2019re designed to perform setup tasks that need to complete before your main application launches \u2014 like setting config values, creating folders, or waiting for external services.</p>"},{"location":"init-containers/#why-use-init-containers","title":"Why Use Init Containers?","text":"<ul> <li>Wait for a database or service to become available</li> <li>Download configuration or secrets from an external source</li> <li>Run database migrations or setup scripts</li> <li>Perform one-time initialization logic before the main app starts</li> </ul> <p>Init containers always run to completion before normal containers are started. If an init container fails, the Pod restarts and tries again.</p>"},{"location":"init-containers/#lifecycle-flow","title":"Lifecycle Flow","text":"<pre><code>flowchart TD\n  start_pod --&gt; init_containers\n  init_containers --&gt; init_success\n  init_success --&gt; main_containers\n\n  start_pod[Start Pod]\n  init_containers[Run Init Containers]\n  init_success[Init Success]\n  main_containers[Run Main Containers]\n</code></pre> <ul> <li>If any init container fails, Kubernetes restarts the entire Pod.</li> <li>Init containers run sequentially, not in parallel.</li> <li>Once completed, they\u2019re never run again.</li> </ul>"},{"location":"init-containers/#example-init-container-waiting-for-service","title":"Example: Init Container Waiting for Service","text":"<pre><code>initContainers:\n  - name: wait-for-db\n    image: busybox\n    command: ['sh', '-c', 'until nc -z db 5432; do sleep 2; done']\n</code></pre> <p>This init container waits for a database service to be reachable on port 5432 before allowing the main container to start.</p>"},{"location":"init-containers/#key-differences-vs-regular-containers","title":"Key Differences vs Regular Containers","text":"Feature Init Container App Container Runs before main app \u2705 \u274c Runs once per Pod \u2705 \u274c Can block Pod startup \u2705 \u274c Restarts separately \u274c (triggers Pod restart) \u2705"},{"location":"init-containers/#summary","title":"Summary","text":"<p>Init containers are a built-in way to prepare your environment before your app runs. They help keep your main containers focused and clean by offloading setup logic. Use them to wait on dependencies, perform one-time actions, or enforce startup ordering.</p>"},{"location":"jobs-cronjobs/","title":"Jobs &amp; CronJobs","text":"<p>Not all workloads in Kubernetes are long-running services. Sometimes, you just need to run something once \u2014 or on a schedule. That\u2019s where Jobs and CronJobs come in.</p>"},{"location":"jobs-cronjobs/#jobs","title":"Jobs","text":"<p>A Job runs a Pod (or set of Pods) to completion. It's ideal for:</p> <ul> <li>One-time tasks</li> <li>Batch processing</li> <li>Migrations or post-deployment hooks</li> </ul> <p>Kubernetes ensures the Job runs successfully to completion \u2014 even if a Pod crashes or a node fails, a new Pod will be scheduled.</p>"},{"location":"jobs-cronjobs/#minimal-job-example","title":"Minimal Job Example","text":"<pre><code>kind: Job\nspec:\n  template:\n    spec:\n      containers:\n        - name: hello\n          image: busybox\n          command: [\"echo\", \"Hello World\"]\n      restartPolicy: Never\n</code></pre> <p>\u24d8 The <code>restartPolicy</code> for Jobs must be <code>Never</code> or <code>OnFailure</code>.</p>"},{"location":"jobs-cronjobs/#cronjobs","title":"CronJobs","text":"<p>A CronJob runs Jobs on a repeating schedule, similar to Linux cron syntax.</p> <p>Use CronJobs for:</p> <ul> <li>Periodic cleanup tasks</li> <li>Scheduled report generation</li> <li>Time-based batch jobs</li> </ul>"},{"location":"jobs-cronjobs/#cron-syntax-example","title":"Cron Syntax Example","text":"<pre><code>kind: CronJob\nspec:\n  schedule: \"0 * * * *\"  # every hour\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: task\n              image: busybox\n              args: [\"echo\", \"Hourly job\"]\n          restartPolicy: OnFailure\n</code></pre> <p>CronJobs use the same <code>jobTemplate</code> spec as regular Jobs.</p>"},{"location":"jobs-cronjobs/#cron-syntax-quick-guide","title":"Cron Syntax Quick Guide","text":"Field Meaning Minute 0\u201359 Hour 0\u201323 Day of Month 1\u201331 Month 1\u201312 Day of Week 0\u20136 (Sun=0) <p>Examples: - <code>0 0 * * *</code> = Every day at midnight - <code>*/5 * * * *</code> = Every 5 minutes</p>"},{"location":"jobs-cronjobs/#summary","title":"Summary","text":"<ul> <li>Use a Job for tasks that need to run once and finish.</li> <li>Use a CronJob to schedule Jobs using cron syntax.</li> <li>Both are useful for batch jobs, cleanup scripts, and other non-service workloads.</li> </ul>"},{"location":"kubernetes-api/","title":"Kubernetes API","text":"<p>The Kubernetes API is the primary interface to interact with your cluster. Whether you\u2019re deploying an app, scaling a workload, inspecting a Pod, or running automation \u2014 you\u2019re using the Kubernetes API.</p> <p>It\u2019s declarative, versioned, extensible, and serves as the backbone of the control plane.</p>"},{"location":"kubernetes-api/#what-is-the-kubernetes-api","title":"What Is the Kubernetes API?","text":"<p>At its core, the API is a RESTful interface that lets you manage API objects such as:</p> <ul> <li>Pods</li> <li>Deployments</li> <li>Services</li> <li>ConfigMaps</li> <li>Namespaces</li> <li>Custom Resources (via CRDs)</li> </ul> <p>Everything in Kubernetes \u2014 from <code>kubectl</code> to the scheduler \u2014 interacts with the API server.</p>"},{"location":"kubernetes-api/#anatomy-of-a-kubernetes-object","title":"Anatomy of a Kubernetes Object","text":"<p>Every resource in Kubernetes follows a common structure:</p> <pre><code>apiVersion: apps/v1          # API group + version\nkind: Deployment             # Type of object\nmetadata:\n  name: my-app\n  namespace: default\nspec:                        # Desired state (defined by user)\n  replicas: 2\nstatus:                      # Actual state (set by the system)\n  replicas: 2\n</code></pre> Field Description <code>apiVersion</code> Group/version the object belongs to <code>kind</code> The object type (e.g., <code>Pod</code>, <code>Service</code>) <code>metadata</code> Info like name, namespace, labels, annotations <code>spec</code> The desired configuration (user-defined) <code>status</code> The actual observed state (set by controllers)"},{"location":"kubernetes-api/#api-server-role","title":"API Server Role","text":"<p>The <code>kube-apiserver</code> is the front door to your cluster. It handles:</p> <ul> <li>All incoming requests from users, <code>kubectl</code>, controllers, and web UIs</li> <li>Validation of requests and schemas</li> <li>Authentication &amp; Authorization</li> <li>Admission control</li> <li>Persisting cluster state in <code>etcd</code></li> </ul> <p>It's stateless and horizontally scalable \u2014 multiple API server instances can run behind a load balancer.</p>"},{"location":"kubernetes-api/#api-request-lifecycle","title":"API Request Lifecycle","text":"<pre><code>flowchart TD\n  A([kubectl apply -f deployment.yaml]) --&gt; B([kube-apiserver])\n  B --&gt; C([Auth \u2b62 RBAC \u2b62 Admission Controllers])\n  C --&gt; D([etcd - stores desired state])\n  D --&gt; E([Controller Manager watches &amp; reacts])\n  E --&gt; F([Scheduler places Pod on Node])\n  F --&gt; G([kubelet starts container])</code></pre>"},{"location":"kubernetes-api/#api-groups-versions","title":"API Groups &amp; Versions","text":"<p>Kubernetes organizes APIs into groups and versions.</p> Path Prefix Group Name Used For <code>/api/v1</code> Core (no group name) Pods, ConfigMaps, Services <code>/apis/apps/v1</code> <code>apps</code> group Deployments, StatefulSets <code>/apis/batch/v1</code> <code>batch</code> group Jobs, CronJobs <code>/apis/networking.k8s.io/v1</code> Networking group Ingress, NetworkPolicies <code>/apis/custom.group/v1</code> Custom Resource group CRDs, Operators <p>You can discover all groups and versions with:</p> <pre><code>kubectl api-versions\nkubectl api-resources\n</code></pre>"},{"location":"kubernetes-api/#crud-via-kubectl","title":"CRUD via kubectl","text":"<p><code>kubectl</code> is a CLI wrapper over raw HTTP requests to the API. Examples:</p> Action HTTP Equivalent <code>kubectl get pods</code> <code>GET /api/v1/namespaces/default/pods</code> <code>kubectl apply -f file.yaml</code> <code>PATCH</code> or <code>POST</code> to relevant endpoint <code>kubectl delete pod nginx</code> <code>DELETE /api/v1/namespaces/default/pods/nginx</code>"},{"location":"kubernetes-api/#declarative-vs-imperative","title":"Declarative vs Imperative","text":"<ul> <li>Imperative: You tell Kubernetes how to do something (<code>kubectl run</code>, <code>kubectl expose</code>)</li> <li>Declarative: You define the desired state, and the system reconciles (<code>kubectl apply -f</code>)</li> </ul> <p>Kubernetes is fundamentally declarative \u2014 the controller manager continually works to match the actual state to the desired state.</p>"},{"location":"kubernetes-api/#working-with-the-api-directly","title":"Working with the API Directly","text":"<p>Enable the API proxy:</p> <pre><code>kubectl proxy\n</code></pre> <p>Browse live cluster data in your browser: http://localhost:8001/api</p> <p>Also try:</p> <pre><code>curl http://localhost:8001/api/v1/namespaces/default/pods\n</code></pre>"},{"location":"kubernetes-api/#custom-resource-definitions-crds","title":"Custom Resource Definitions (CRDs)","text":"<p>CRDs allow you to extend the Kubernetes API with your own types.</p> <p>Example:</p> <pre><code>apiVersion: myteam.example.com/v1\nkind: Widget\nmetadata:\n  name: widget-123\nspec:\n  color: blue\n  size: large\n</code></pre> <p>This adds a new resource (<code>Widget</code>) to the cluster. Common in Operators.</p>"},{"location":"kubernetes-api/#api-security-flow","title":"API Security Flow","text":"<p>Every API request goes through:</p> <ol> <li>Authentication \u2013 Who is making the request?</li> <li>Authorization (RBAC) \u2013 Are they allowed to perform this action?</li> <li>Admission Controllers \u2013 Mutate or validate the request</li> <li>Validation \u2013 Is the object schema correct?</li> <li>Persistence \u2013 If approved, store in etcd</li> </ol> <p>RBAC example:</p> <pre><code>kind: Role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"list\"]\n</code></pre>"},{"location":"kubernetes-api/#common-trouble-spots","title":"Common Trouble Spots","text":"<ul> <li>Wrong API version: Resources can move or deprecate (e.g., <code>apps/v1beta1</code> is deprecated)</li> <li>Incorrect Group: Always verify the group (e.g., <code>networking.k8s.io</code> vs <code>extensions</code>)</li> <li>Unregistered CRDs: You can\u2019t use a CRD before applying its definition</li> </ul>"},{"location":"kubernetes-api/#summary","title":"Summary","text":"<ul> <li>The API server is the core of the Kubernetes control plane.</li> <li>Everything \u2014 even <code>kubectl</code> commands \u2014 maps to API calls.</li> <li>Understand the object structure (<code>apiVersion</code>, <code>kind</code>, <code>metadata</code>, <code>spec</code>)</li> <li>Know how groups, versions, and resources are organized and discovered</li> <li>CRDs allow teams to define custom workflows</li> <li>All requests flow through authentication, authorization, and admission control before being persisted and acted upon</li> </ul>"},{"location":"limits-requests/","title":"Resource Requests &amp; Limits","text":"<p>Kubernetes lets you control how much CPU and memory each container is guaranteed and allowed to use. This is done through resource requests and limits in the container spec.</p>"},{"location":"limits-requests/#requests-vs-limits","title":"Requests vs Limits","text":"Term Purpose Scheduler Uses? Enforced at Runtime? <code>requests</code> Minimum resources guaranteed to a container \u2705 Yes \u274c No <code>limits</code> Maximum resources a container can use \u274c No \u2705 Yes <ul> <li>Requests are used during scheduling. Kubernetes places Pods on nodes that can satisfy their requested resources.</li> <li>Limits prevent a container from exceeding a set threshold.</li> </ul>"},{"location":"limits-requests/#example-cpu-and-memory-settings","title":"Example: CPU and Memory Settings","text":"<pre><code>resources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"250m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n</code></pre> <p>This guarantees the container gets at least 256Mi and 250 millicores, but it cannot exceed 512Mi or 500 millicores.</p>"},{"location":"limits-requests/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Too low requests \u2192 Your Pod may get scheduled on a crowded node and experience performance issues.</li> <li>No limits \u2192 A container can consume all resources and cause noisy neighbor problems.</li> <li>Too low limits \u2192 Can result in OOMKills or throttled CPU.</li> </ul>"},{"location":"limits-requests/#cpu-behavior","title":"CPU Behavior","text":"<ul> <li>If a container exceeds its CPU limit, it is throttled \u2014 not killed.</li> <li>If you don\u2019t set a limit, the container may consume all available CPU.</li> </ul>"},{"location":"limits-requests/#memory-behavior","title":"Memory Behavior","text":"<ul> <li>If memory usage exceeds the limit, the container is killed with an OOMKill (Out of Memory).</li> <li>Kubernetes does not restart it unless it's part of a higher-level controller (like a Deployment).</li> </ul>"},{"location":"limits-requests/#best-practices","title":"Best Practices","text":"<ul> <li>Always set both requests and limits \u2014 especially for memory.</li> <li>Set realistic requests to ensure proper scheduling.</li> <li>Avoid overly restrictive limits unless you're debugging or need to enforce strict control.</li> <li>Use LimitRanges or ResourceQuotas to apply default or max values across a namespace.</li> </ul>"},{"location":"limits-requests/#summary","title":"Summary","text":"<ul> <li>Requests = what your container is guaranteed</li> <li>Limits = the hard ceiling your container can use</li> <li>Kubernetes uses requests for scheduling and limits for enforcement.</li> <li>Proper resource settings help with performance, predictability, and cluster stability.</li> </ul>"},{"location":"local-setup/","title":"Local setup","text":""},{"location":"local-setup/#getting-a-local-kubernetes-cluster","title":"Getting a Local Kubernetes Cluster","text":"<p>For most users, setting up a local Kubernetes cluster using Docker Desktop or KinD (Kubernetes in Docker) is the best option when learning. It's free and allows you to quickly and easily get your hands on and start playing with Kubernetes.</p> Option 1: Docker Desktop <p>Docker Desktop is a straightforward way to get Docker, Kubernetes, and <code>kubectl</code> on your computer, along with a user-friendly interface for managing your cluster contexts.</p> <p>Install Docker Desktop:</p> <p>Download and run the installer for your operating system from the Docker website. Follow the installation prompts. For Windows users, install the WSL 2 subsystem when prompted.</p> <p>Enable Kubernetes in Docker Desktop:</p> <p>Click the Docker icon in your menu bar or system tray and go to Settings. Select \"Kubernetes\" from the left navigation bar. Check \"Enable Kubernetes\" and click \"Apply &amp; restart.\" Wait a few minutes for Docker Desktop to pull the required images and start the cluster. The Kubernetes icon in the Docker Desktop window will turn green when the cluster is ready.</p> <p>Verify the Installation:</p> <p>Open a terminal and run the following commands to ensure Docker and <code>kubectl</code> are installed and working:</p> <pre><code>docker --version\nkubectl version --client=true -o yaml\n</code></pre> <p>Ensure the cluster is running with:</p> <p><pre><code>kubectl get nodes\n</code></pre> This command lists all the nodes in your Kubernetes cluster. You should see at least one node listed, confirming your cluster is up and running.</p> Option 2: KinD <p>KinD (Kubernetes in Docker) is an excellent tool for running local Kubernetes clusters using Docker containers. It\u2019s lightweight, flexible, and ideal for development and testing. It's my tool of choice for local development/experimentation.</p> <p>Install KinD:</p> <p>Follow the instructions on the KinD GitHub page to install KinD on your system. For macOS users, you can simply run <code>brew install kind</code> to get up and running quickly.</p> <p>Create a KinD Cluster:</p> <p><pre><code>kind create cluster\n</code></pre> This command sets up a new Kubernetes cluster locally using Docker containers. KinD creates a single-node cluster by default, which is sufficient for most development and testing needs.</p> <p>Verify your cluster is running:</p> <p><pre><code>kubectl get nodes\n</code></pre> This command lists all the nodes in your Kubernetes cluster. You should see the node created by KinD, confirming your cluster is up and running.</p> Alternative Tools <p>While Docker Desktop and KinD are popular choices, other tools like Minikube or k3d can also be used to set up local Kubernetes clusters. These tools offer different features and may better suit specific needs or preferences.</p>"},{"location":"local-setup/#working-with-kubectl","title":"Working with kubectl","text":"<p><code>kubectl</code> is the command-line tool used to interact with your Kubernetes clusters. It's essential for deploying applications, inspecting and managing cluster resources, and troubleshooting issues.</p> Installation <p>If you've followed the steps to set up either Docker Desktop or KinD, you should already have <code>kubectl</code> installed. If not, you can install it separately:</p> <p>Linux:</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin/\n</code></pre> <p>Mac:</p> <pre><code>brew install kubectl\n</code></pre> <p>Windows:</p> <p>Download the executable from the official Kubernetes site and add it to your system PATH.</p> Using kubectl <p>Once installed, <code>kubectl</code> allows you to perform various operations on your Kubernetes cluster. Here are a few basic commands to get you started:</p> <p>Check Cluster Nodes: <pre><code>kubectl get nodes\n</code></pre> This command lists all nodes in the cluster, showing their status, roles, and other details.</p> <p>Get Cluster Info: <pre><code>kubectl cluster-info\n</code></pre> This command displays information about the cluster, including the URL of the Kubernetes master and other components.</p> <p>Deploy an Application: <pre><code>kubectl apply -f &lt;filename&gt;.yaml\n</code></pre> This command applies a configuration file to the cluster, creating or updating resources defined in the file.</p> <p>Inspect Resources: <pre><code>kubectl get pods\nkubectl describe pod &lt;pod-name&gt;\n</code></pre> These commands list all pods in the cluster and provide detailed information about a specific pod, respectively.</p> Setting an Alias for kubectl <p>Instead of typing out <code>kubectl</code> for every command, many Kubernetes users set an alias for it by adding the following to their shell profile:</p> <p><pre><code>alias k=kubectl\n</code></pre> This way, you can use <code>k</code> instead of <code>kubectl</code> in your commands, saving time and effort.</p> <p>Tip</p> <p>Using aliases can significantly speed up your workflow and reduce the chances of making typos in long commands.</p>"},{"location":"local-setup/#summary","title":"Summary","text":"<p>Setting up a local Kubernetes cluster using Docker Desktop or KinD is a great way to get hands-on experience with Kubernetes. Both tools provide an easy and quick way to start working with Kubernetes, allowing you to experiment and learn in a controlled environment. With <code>kubectl</code>, you can manage your cluster and deploy applications, making it an essential tool for any Kubernetes user.</p>"},{"location":"maintenance/","title":"Kubernetes Maintenance","text":"<p>Regular maintenance is essential for ensuring the stability and performance of your Kubernetes clusters. This section covers key maintenance activities, including upgrading clusters, nodes, Kubernetes versions, and operating systems.</p>"},{"location":"maintenance/#upgrading-kubernetes-clusters","title":"Upgrading Kubernetes Clusters","text":"Cluster Upgrades <p>Upgrading your Kubernetes cluster ensures you have the latest features, security patches, and performance improvements.</p> <ol> <li> <p>Plan the Upgrade</p> <ul> <li>Review release notes and determine upgrade path.</li> <li>Backup critical data and verify integrity.</li> <li>Test the upgrade process in a staging environment.</li> </ul> </li> <li> <p>Perform the Upgrade</p> <ul> <li>Follow your Kubernetes distribution's upgrade documentation.</li> <li>Monitor the upgrade process and be ready to roll back if needed.</li> </ul> </li> </ol> Node Upgrades <ol> <li> <p>Prepare Nodes</p> <ul> <li>Drain nodes using <code>kubectl drain &lt;node-name&gt;</code>.</li> <li>Upgrade Kubernetes components and OS packages.</li> </ul> </li> <li> <p>Rejoin Cluster</p> <ul> <li>Use <code>kubectl uncordon &lt;node-name&gt;</code> to bring nodes back online.</li> </ul> </li> </ol>"},{"location":"maintenance/#upgrading-kubernetes-versions","title":"Upgrading Kubernetes Versions","text":"<ol> <li> <p>Check Compatibility</p> <ul> <li>Review the version skew policy to ensure compatibility across your environment.</li> <li>Review deprecated features and update manifests.</li> <li>Test applications in a staging environment.</li> </ul> </li> <li> <p>Upgrade Control Plane and Nodes</p> <ul> <li>Follow official Kubernetes documentation for upgrading components.</li> <li>Upgrade <code>kubelet</code> and <code>kubectl</code> on nodes.</li> </ul> </li> </ol>"},{"location":"maintenance/#best-practices","title":"Best Practices","text":"<ul> <li>Regularly audit cluster configurations and security settings.</li> <li>Document maintenance activities and changes.</li> <li>Implement automated backup solutions to protect critical data.</li> </ul>"},{"location":"namespaces/","title":"Namespaces","text":"<p>Namespaces in Kubernetes allow you to divide cluster resources between multiple users or teams. They provide logical isolation and help with multi-tenancy, access control, and resource management.</p>"},{"location":"namespaces/#when-to-use-namespaces","title":"When to Use Namespaces","text":"<p>Namespaces are useful when:</p> <ul> <li>You need to isolate environments (e.g., <code>dev</code>, <code>staging</code>, <code>prod</code>)</li> <li>You want to enforce resource quotas and limits</li> <li>You want to implement RBAC per team or application</li> </ul> <p>For most small or single-team clusters, the <code>default</code> namespace is sufficient.</p>"},{"location":"namespaces/#viewing-namespaces","title":"Viewing Namespaces","text":"<pre><code>kubectl get namespaces\n</code></pre> <p>Or with shorthand:</p> <pre><code>kubectl get ns\n</code></pre>"},{"location":"namespaces/#creating-a-namespace","title":"Creating a Namespace","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev-team\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f namespace.yaml\n</code></pre>"},{"location":"namespaces/#using-namespaces-with-kubectl","title":"Using Namespaces with kubectl","text":"<pre><code>kubectl get pods -n dev-team\nkubectl create deployment nginx --image=nginx -n dev-team\n</code></pre> <p>To temporarily switch namespace context:</p> <pre><code>kubectl config set-context --current --namespace=dev-team\n</code></pre>"},{"location":"namespaces/#default-namespaces","title":"Default Namespaces","text":"Namespace Purpose <code>default</code> Used when no other namespace is specified <code>kube-system</code> Kubernetes control plane components (DNS, scheduler) <code>kube-public</code> Readable by all users, often used for public bootstrap <code>kube-node-lease</code> Heartbeats for node status"},{"location":"namespaces/#namespaced-vs-cluster-scoped-resources","title":"Namespaced vs Cluster-Scoped Resources","text":"<p>Some resources must live in a namespace, others are cluster-scoped.</p> Namespaced Cluster-Scoped Pods, Deployments, PVCs Nodes, PersistentVolumes ConfigMaps, Secrets Namespaces, CRDs Services StorageClasses, RBAC Roles"},{"location":"namespaces/#resource-quotas-and-limits","title":"Resource Quotas and Limits","text":"<p>You can enforce limits on namespaces using:</p> <ul> <li><code>ResourceQuota</code>: caps total resources in the namespace</li> <li><code>LimitRange</code>: sets default limits per Pod/container</li> </ul> <p>Example:</p> <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-quota\n  namespace: dev\nspec:\n  hard:\n    requests.cpu: \"2\"\n    limits.memory: 4Gi\n</code></pre>"},{"location":"namespaces/#cleanup","title":"Cleanup","text":"<p>To delete a namespace and everything inside it:</p> <pre><code>kubectl delete namespace dev-team\n</code></pre>"},{"location":"namespaces/#summary","title":"Summary","text":"<ul> <li>Namespaces are key to organizing, isolating, and managing Kubernetes resources.</li> <li>Use them for multi-tenancy, RBAC, and resource quotas.</li> <li>Know which resources are namespaced vs. cluster-scoped.</li> </ul>"},{"location":"netpol/","title":"Network Policies","text":"<p>By default, all Pods in a Kubernetes cluster can talk to each other. This is convenient, but risky \u2014 especially in multi-tenant clusters or production environments.</p> <p>NetworkPolicies let you control which Pods can talk to which other Pods (and even external IPs).</p> <p>Think of it like a firewall for Pod-to-Pod traffic \u2014 but defined in YAML.</p>"},{"location":"netpol/#key-concepts","title":"Key Concepts","text":"<ul> <li>NetworkPolicies apply to Pods (via label selectors)</li> <li>They control ingress, egress, or both</li> <li>They require a network plugin (CNI) that supports them (e.g., Calico, Cilium)</li> </ul> <p>No policies = allow all Any policy = default deny (for the targeted direction)</p>"},{"location":"netpol/#minimal-example","title":"Minimal Example","text":"<p>Allow only traffic to a Pod from Pods with a specific label:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-frontend\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: backend\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              app: frontend\n</code></pre> <p>This says: Only Pods labeled <code>app=frontend</code> can access Pods labeled <code>app=backend</code>.</p>"},{"location":"netpol/#policy-scope","title":"Policy Scope","text":"Field Controls <code>podSelector</code> Which Pods the policy applies to <code>ingress</code> Who can reach the Pod <code>egress</code> Where the Pod is allowed to send traffic"},{"location":"netpol/#egress-example","title":"Egress Example","text":"<pre><code>egress:\n  - to:\n      - ipBlock:\n          cidr: 10.0.0.0/24\n    ports:\n      - protocol: TCP\n        port: 443\n</code></pre> <p>This allows outbound HTTPS traffic only to <code>10.0.0.0/24</code>.</p>"},{"location":"netpol/#tips-gotchas","title":"Tips &amp; Gotchas","text":"<ul> <li>If a Pod is not selected by any policy, it is open by default</li> <li>If a Pod is selected, and you define <code>ingress</code>, all other traffic is denied</li> <li>You must allow DNS explicitly if you restrict egress (e.g., UDP 53)</li> <li>Labels matter \u2014 both on the target and the allowed sources</li> </ul>"},{"location":"netpol/#cni-support","title":"CNI Support","text":"<p>Not all network plugins support NetworkPolicies. Some common ones that do:</p> <ul> <li>\u2705 Calico</li> <li>\u2705 Cilium</li> <li>\u2705 Antrea</li> <li>\u274c Flannel (without plugins)</li> <li>\u274c Amazon VPC CNI (limited support unless enhanced)</li> </ul>"},{"location":"netpol/#summary","title":"Summary","text":"<ul> <li>NetworkPolicies control Pod-level traffic based on labels and CIDRs</li> <li>Define who can talk to what, and where traffic can go</li> <li>Essential for zero-trust network design inside the cluster</li> <li>Start with <code>ingress</code> rules, then layer on <code>egress</code> if needed</li> </ul>"},{"location":"networking/","title":"Networking Overview","text":"<p>Networking in Kubernetes is simple on the surface, but powerful under the hood. Every Pod gets an IP address, Services provide stable endpoints, and the network model enables communication across the entire cluster \u2014 often without needing to understand the low-level implementation details.</p>"},{"location":"networking/#core-principles-of-kubernetes-networking","title":"Core Principles of Kubernetes Networking","text":"<ol> <li>Each Pod gets a unique IP</li> <li>No NAT between Pods</li> <li> <p>All containers within a Pod share the same network namespace</p> </li> <li> <p>All Pods can reach each other</p> </li> <li> <p>Flat network model (no IP masquerading between Pods)</p> </li> <li> <p>Services provide stable access to Pods</p> </li> <li>Pods are ephemeral \u2014 Services give them a consistent IP + DNS name</li> </ol>"},{"location":"networking/#network-abstraction-layers","title":"Network Abstraction Layers","text":"Layer Purpose Pod Network Every Pod gets an IP, routable in-cluster Service Provides a stable endpoint for Pod groups Ingress Exposes HTTP/S services externally NetworkPolicy Controls traffic between Pods (optional)"},{"location":"networking/#dns-in-kubernetes","title":"DNS in Kubernetes","text":"<p>Kubernetes includes built-in DNS resolution for:</p> <ul> <li>Services: <code>my-service.my-namespace.svc.cluster.local</code></li> <li>Pods (not recommended for direct use)</li> </ul> <p>DNS is powered by CoreDNS by default, running in the <code>kube-system</code> namespace.</p> <pre><code>nslookup my-service.default.svc.cluster.local\n</code></pre>"},{"location":"networking/#pod-to-pod-communication","title":"Pod-to-Pod Communication","text":"<ul> <li>All Pods are routable via their internal IP addresses</li> <li>No need for manual port forwarding</li> <li>Backed by a Container Network Interface (CNI) plugin (e.g., Calico, Flannel)</li> </ul>"},{"location":"networking/#service-types-covered-in-next-section","title":"Service Types (Covered in next section)","text":"<ul> <li><code>ClusterIP</code> \u2013 default; internal-only</li> <li><code>NodePort</code> \u2013 exposes via node IP + static port</li> <li><code>LoadBalancer</code> \u2013 provision external LB (cloud)</li> <li><code>ExternalName</code> \u2013 maps to external DNS</li> </ul>"},{"location":"networking/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Kubernetes assumes a flat, open network where every Pod can talk to every other Pod</li> <li>You don\u2019t need to assign IPs or manage routes \u2014 the CNI plugin does that</li> <li>Communication is typically via Service abstraction, not direct Pod IPs</li> <li>You can add NetworkPolicies to restrict traffic if needed</li> </ul>"},{"location":"networking/#summary","title":"Summary","text":"<ul> <li>Every Pod gets an IP \u2014 networking is native, not container-to-container port mapping</li> <li>Services, not Pods, are the preferred way to access applications</li> <li>DNS is built-in and resolves Services by name</li> <li>You don\u2019t manage the network manually \u2014 but understanding its behavior is essential</li> </ul>"},{"location":"operators-crds/","title":"Kubernetes Operators and Custom Resource Definitions (CRDs)","text":"<p>Kubernetes Operators and CRDs extend the functionality of Kubernetes by allowing you to manage complex applications and define custom resources tailored to your needs.</p>"},{"location":"operators-crds/#understanding-operators","title":"Understanding Operators","text":"What are Operators? <p>Operators are software extensions that use custom resources to manage applications and their components. They automate tasks beyond the capabilities of standard Kubernetes resources, following Kubernetes principles like the control loop.</p> Purpose of Operators <p>Operators automate the lifecycle of complex applications, including:</p> <ul> <li>Installation: Deploying and configuring applications.</li> <li>Management: Managing runtime configurations.</li> <li>Scaling: Adjusting resources based on workloads.</li> <li>Healing: Detecting and recovering from failures.</li> <li>Upgrades: Updating applications to new versions.</li> </ul> Benefits of Using Operators <ul> <li>Consistency: Provides a consistent way to manage applications.</li> <li>Automation: Reduces manual intervention.</li> <li>Scalability: Manages resources efficiently.</li> </ul> Advanced Operator Features <ul> <li>Event Handling: Operators can respond to Kubernetes events to maintain desired state.</li> <li>Custom Metrics: Use custom metrics to make informed scaling decisions.</li> <li>Backup and Restore: Implement application-specific backup and restore logic.</li> </ul>"},{"location":"operators-crds/#understanding-custom-resource-definitions-crds","title":"Understanding Custom Resource Definitions (CRDs)","text":"Introduction to CRDs <p>CRDs allow you to define custom resources within the Kubernetes API, enabling the management of application-specific data and configurations.</p> Benefits of Using CRDs <ul> <li>Custom Resources: Tailor resources to your application's needs.</li> <li>Declarative Management: Use Kubernetes' API for management.</li> <li>Integration: Seamlessly integrate with Kubernetes tools.</li> </ul> Advanced CRD Features <ul> <li>Schema Validation: Define validation rules for custom resources to ensure data integrity.</li> <li>Versioning: Manage different versions of CRDs to support application evolution.</li> <li>Subresources: Use subresources like status and scale for additional functionality.</li> </ul> Creating a CRD <p>Define a CRD in a YAML file and apply it to your cluster.</p> <p>Example CRD Definition: <pre><code>apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: widgets.example.com\nspec:\n  group: example.com\n  versions:\n    - name: v1\n      served: true\n      storage: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                size:\n                  type: string\n                color:\n                  type: string\n  scope: Namespaced\n  names:\n    plural: widgets\n    singular: widget\n</code></pre></p>"},{"location":"operators-crds/#creating-and-deploying-operators","title":"Creating and Deploying Operators","text":"Developing an Operator <p>Develop an Operator by defining custom resources and implementing controllers.</p> <pre><code># Install the Operator SDK\ncurl -LO https://github.com/operator-framework/operator-sdk/releases/download/v1.0.0/operator-sdk_linux_amd64\nchmod +x operator-sdk_linux_amd64\nsudo mv operator-sdk_linux_amd64 /usr/local/bin/operator-sdk\n\n# Create a new Operator project\noperator-sdk init --domain=example.com --repo=github.com/example-inc/memcached-operator\n\n# Define a new API\noperator-sdk create api --group cache --version v1alpha1 --kind Memcached --resource --controller\n</code></pre>"},{"location":"operators-crds/#best-practices","title":"Best Practices","text":"<ul> <li>Version Control: Use version control for Operator code and CRDs.</li> <li>Testing: Implement thorough testing to ensure reliability.</li> <li>Documentation: Provide clear documentation for usage and maintenance.</li> <li>Security: Follow security best practices to protect data and configurations.</li> </ul>"},{"location":"overview/","title":"Getting Started","text":""},{"location":"overview/#introduction-to-kubernetes","title":"Introduction to Kubernetes","text":"<p>Kubernetes, often referred to as K8s, is an open-source platform designed to automate deploying, scaling, and operating application containers. Originally developed by Google, it is now maintained by the Cloud Native Computing Foundation (CNCF). This section provides an essential overview of Kubernetes, its architecture, and key features to get you started.</p>"},{"location":"overview/#what-is-kubernetes","title":"What is Kubernetes?","text":"<p>Kubernetes is a powerful container orchestrator that manages the deployment and operation of containerized applications. Containers are lightweight, portable units that bundle an application and its dependencies, allowing them to run consistently across different environments. Kubernetes automates several tasks:</p> <ul> <li>Deployment: Seamlessly deploys applications by creating and managing containers.</li> <li>Scaling: Adjusts the number of application instances based on demand, ensuring efficient use of resources.</li> <li>Self-healing: Detects and replaces failed instances to maintain application availability.</li> <li>Rolling Updates and Rollbacks: Updates applications without downtime and rolls back to a previous version if needed.</li> </ul>"},{"location":"overview/#key-concepts-of-kubernetes","title":"Key Concepts of Kubernetes","text":"Declarative Model <p>Kubernetes operates on a declarative model, where you specify the desired state of the system in YAML or JSON configuration files. The system continuously works to ensure the observed state matches the desired state. This involves three key principles:</p> <ol> <li>Observed State: The current state of the system.</li> <li>Desired State: The state you want the system to achieve.</li> <li>Reconciliation: The process of adjusting the observed state to match the desired state.</li> </ol> <p>The declarative nature of Kubernetes is key to understanding its power. At a high level, here's how it works:</p> <ol> <li>You tell Kubernetes (typically via <code>kubectl</code>) how you want your application to look\u2014what image to use, how many replicas, ports to expose, etc.</li> <li>Kubernetes persists this desired state to the cluster store (etcd).</li> <li>A series of background controllers consistently check if the current state matches the desired state.</li> <li>If the current state does not equal the desired state (e.g., you desire 3 replicas but only 2 are currently running), the API Server is notified and,</li> <li>Kubernetes initiates actions to reconcile the two states.</li> </ol> Declarative Approach in Kubernetes <p>Kubernetes uses a declarative approach to manage resources. This means you define the desired state of the system and Kubernetes works to maintain that state.</p> <pre><code>sequenceDiagram\n    participant User\n    participant APIServer as API Server\n    participant etcd\n    participant Controller as Controller Manager\n    participant Scheduler\n\n    User-&gt;&gt;APIServer: 1. Declare desired state\n    APIServer-&gt;&gt;etcd: 2. Persist desired state\n\n    Controller-&gt;&gt;APIServer: 3. Check actual vs. desired\n    APIServer--&gt;&gt;Controller: current != desired\n    Controller-&gt;&gt;APIServer: Reconcile differences\n\n    APIServer-&gt;&gt;Scheduler: Trigger scheduling if needed</code></pre> <p>This diagram illustrates how Kubernetes manages resources declaratively, ensuring the system's state aligns with the user's specifications.</p> Kubernetes Architecture <p>Kubernetes architecture consists of several key components:</p> <ul> <li>API Server: The front-end for the Kubernetes control plane, handling all REST operations.</li> <li>etcd: A consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data.</li> <li>Scheduler: Assigns workloads to nodes based on resource availability.</li> <li>Controller Manager: Runs controllers to regulate the state of the cluster.</li> <li>Kubelet: Ensures containers are running in a Pod on each node.</li> </ul> Services <p>Services provide stable networking endpoints for Pods, enabling reliable communication between different parts of an application. They abstract away the ephemeral nature of Pods, which can be created and destroyed dynamically, and give you a stable, long-lived connection point to the underlying Pods.</p>"},{"location":"overview/#historical-background","title":"Historical Background","text":"<p>Kubernetes was born from Google's internal systems like Borg and Omega, which managed containerized applications like Search and Gmail at a massive scale. In 2014, Google open-sourced Kubernetes, and it quickly became the standard for container orchestration.</p>"},{"location":"overview/#common-features-primer","title":"Common Features Primer","text":"Pods and Deployments <ul> <li>Pods: The smallest deployable units in Kubernetes, which can contain one or more containers. Containers within Pods share resources like network and storage.</li> <li>Deployments: Higher-level controllers that manage Pods, providing features like scaling, rolling updates, and rollbacks.</li> </ul> Self-Healing and Scaling <p>If deployed as part of a Deployment or StatefulSet, Kubernetes will automatically replace failed Pods and scale your application up or down based on traffic, load, or other custom thresholds. This ensures high availability and efficient resource utilization.</p> Rolling Updates and Rollbacks <p>By leveraging Deployments (via ReplicaSets), Kubernetes allows you to update your application without downtime by gradually replacing old Pods with new ones. If something goes wrong, Kubernetes can roll back to the previous version.</p>"},{"location":"overview/#summary","title":"Summary","text":"<p>Kubernetes is a powerful tool for managing containerized applications, offering automation, scalability, and reliability. By abstracting the underlying infrastructure, it simplifies application deployment and management across various environments. Whether you're running on-premises or in the cloud, Kubernetes provides a consistent and efficient platform for your applications. Before diving into some more details on these topics, let's first cover how you can quickly get your hands on a Kubernetes environment in the next section.</p>"},{"location":"pods-deployments/","title":"Pods &amp; Deployments","text":"<p>In Kubernetes, Pods are the foundational execution units\u2014everything runs in a Pod. But on their own, Pods aren't typically used directly in production environments. Instead, Deployments manage Pods to provide automation, self-healing, and declarative updates.</p>"},{"location":"pods-deployments/#what-is-a-pod","title":"What is a Pod?","text":"<p>A Pod is the smallest deployable unit in Kubernetes. It represents one or more containers that share:</p> <ul> <li>The same network namespace (IP address and port space).</li> <li>A shared storage volume (if defined).</li> <li>The same lifecycle (they are scheduled and managed together).</li> </ul> <p>Typically, a Pod contains a single container, but multi-container Pods are used when tightly coupled containers need to share resources, such as a sidecar pattern.</p> <p>Key traits of Pods:</p> <ul> <li>Pods are ephemeral and disposable.</li> <li>Pods do not self-heal if they crash or are evicted.</li> <li>Pods are bound to a specific Node until terminated.</li> </ul> <p> </p> <pre><code>flowchart TD \n    subgraph \"Pod\"\n        subgraph \"container\"\n        H[\"application\"]\n        end\n    end</code></pre>"},{"location":"pods-deployments/#what-is-a-deployment","title":"What is a Deployment?","text":"<p>A Deployment is a higher-level Kubernetes resource that manages a ReplicaSet, which in turn manages the lifecycle of multiple identical Pods.</p> <p>With Deployments, you get:</p> <ul> <li>Declarative management of Pod replicas</li> <li>Rolling updates and rollbacks</li> <li>Auto-replacement of failed Pods</li> <li>Declarative versioning of your app</li> </ul> <p>You define the desired state in a <code>Deployment</code> YAML file, and the Kubernetes control plane ensures that the running state matches it.</p>"},{"location":"pods-deployments/#relationship-between-pods-and-deployments","title":"Relationship Between Pods and Deployments","text":"<p>Think of a Pod like a coffee machine in a busy caf\u00e9. It makes drinks, does its job, and eventually wears out or breaks.</p> <p>Now imagine the Deployment as the caf\u00e9 manager:</p> <ul> <li>They make sure there are always enough coffee machines running.</li> <li>If one breaks, they replace it.</li> <li>If demand increases, they bring in more.</li> <li>If an update to the machine model is needed, they roll them out gradually and safely.</li> </ul> <p>So while a Pod is the worker, the Deployment manages the workforce and ensures consistency, scalability, and resiliency over time.</p> <p>A Deployment always manages Pods\u2014you typically never run a Deployment without Pods.</p> <p>When you apply a Deployment spec:</p> <ol> <li>Kubernetes creates a ReplicaSet.</li> <li>The ReplicaSet creates the desired number of Pods.</li> <li>If any Pod dies, the ReplicaSet spawns a replacement.</li> </ol>"},{"location":"pods-deployments/#when-to-use-what","title":"When to Use What?","text":"<p>Use Pods directly:</p> <ul> <li>In static dev/test environments.</li> <li>For one-off jobs (though <code>Job</code> is preferred).</li> <li>For simple single-Pod debugging.</li> </ul> <p>Use Deployments:</p> <ul> <li>Always, for production services.</li> <li>When you need replication, availability, and self-healing.</li> <li>If you plan to roll out updates with zero downtime.</li> </ul>"},{"location":"psa/","title":"Pod Security","text":"<p>Pod Security Admission (PSA) is the built-in mechanism in Kubernetes for enforcing security standards on Pods at the API level. Introduced in Kubernetes v1.22 and stable in v1.25, it replaced the deprecated PodSecurityPolicy (PSP) feature.</p> <p>PSA evaluates Pod specifications during creation or update and applies policy controls based on predefined security profiles.</p>"},{"location":"psa/#key-concepts","title":"Key Concepts","text":"<p>PSA is implemented as an admission controller that checks incoming Pod specs and enforces or audits their compliance with a chosen security profile.</p> <p>There are three policy levels, each defining a different set of security requirements:</p> Level Description <code>privileged</code> No restrictions \u2014 full access to host features <code>baseline</code> Minimally restrictive, prevents known high-risk settings <code>restricted</code> Highly restrictive, follows best practices for multi-tenant hardening <p>Each namespace can have policies assigned in one of three modes:</p> Mode Description <code>enforce</code> Reject non-compliant Pods <code>audit</code> Log violations but allow the Pod <code>warn</code> Send warnings to the user, but allow the Pod"},{"location":"psa/#configuring-psa","title":"Configuring PSA","text":"<p>PSA is enabled by default in modern Kubernetes clusters. You can configure policy levels on a per-namespace basis using labels.</p>"},{"location":"psa/#example-apply-restricted-policy-with-all-modes","title":"Example: Apply <code>restricted</code> policy with all modes","text":"<pre><code>kubectl label namespace secure-ns \\\n  pod-security.kubernetes.io/enforce=restricted \\\n  pod-security.kubernetes.io/enforce-version=latest \\\n  pod-security.kubernetes.io/audit=restricted \\\n  pod-security.kubernetes.io/audit-version=latest \\\n  pod-security.kubernetes.io/warn=restricted \\\n  pod-security.kubernetes.io/warn-version=latest\n</code></pre> <p>This enforces, audits, and warns against any pod that doesn\u2019t meet the <code>restricted</code> policy level.</p>"},{"location":"psa/#policy-examples","title":"Policy Examples","text":"<p>Here are a few settings disallowed at each level:</p> Setting baseline restricted <code>hostNetwork: true</code> \u274c \u274c <code>privileged: true</code> \u274c \u274c <code>runAsNonRoot: false</code> \u2705 \u274c <code>allowPrivilegeEscalation: true</code> \u2705 \u274c <code>capabilities.add: [\"ALL\"]</code> \u274c \u274c <p>For full definitions, refer to the Kubernetes Pod Security Standards.</p>"},{"location":"psa/#when-to-use-each-profile","title":"When to Use Each Profile","text":"Use Case Recommended Level Development namespace baseline CI/CD pipelines baseline Multi-tenant cluster workloads restricted System workloads or privileged apps privileged"},{"location":"psa/#best-practices","title":"Best Practices","text":"<ul> <li>Apply PSA labels early in your cluster setup.</li> <li>Use <code>audit</code> and <code>warn</code> modes first to test compliance before enforcing.</li> <li>Combine PSA with RBAC and admission webhooks for layered security.</li> <li>Use <code>kubectl run</code> and <code>kubectl apply</code> in secure ways to avoid bypassing policy checks.</li> <li>Regularly review and adjust policy levels as your workloads evolve.</li> </ul>"},{"location":"psa/#summary","title":"Summary","text":"<p>Pod Security Admission (PSA) provides a native, stable way to enforce pod-level security standards in Kubernetes. By labeling namespaces with the appropriate levels and modes, you can create secure boundaries around workloads and minimize exposure to unsafe configurations.</p>"},{"location":"quotas-limits/","title":"Quotas & Limits","text":"<p>In a multi-tenant Kubernetes environment, it's important to prevent any single team, namespace, or workload from consuming all available cluster resources. Kubernetes provides two mechanisms to enforce this: ResourceQuotas and LimitRanges.</p> <p>These tools help cluster administrators enforce fair resource allocation, cost controls, and capacity planning across teams and environments.</p>"},{"location":"quotas-limits/#resourcequota","title":"ResourceQuota","text":"<p>A ResourceQuota defines a hard cap on the total resource usage (CPU, memory, object counts, etc.) within a namespace.</p> <p>If the total usage across all Pods in the namespace exceeds the defined quota, further resource requests will be denied.</p>"},{"location":"quotas-limits/#example-memory-cpu-quota","title":"Example: Memory &amp; CPU Quota","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: dev-quota\n  namespace: dev\nspec:\n  hard:\n    requests.cpu: \"2\"\n    requests.memory: \"4Gi\"\n    limits.cpu: \"4\"\n    limits.memory: \"8Gi\"\n</code></pre> <p>This restricts total requested and limited CPU/memory for all Pods in the <code>dev</code> namespace.</p>"},{"location":"quotas-limits/#example-object-count-quota","title":"Example: Object Count Quota","text":"<pre><code>spec:\n  hard:\n    pods: \"10\"\n    configmaps: \"20\"\n    persistentvolumeclaims: \"5\"\n</code></pre> <p>You can limit the number of objects like Pods, ConfigMaps, or PVCs to enforce soft multi-tenancy boundaries.</p>"},{"location":"quotas-limits/#limitrange","title":"LimitRange","text":"<p>A LimitRange sets default values and upper/lower bounds for container-level resource usage within a namespace.</p> <p>It ensures developers don\u2019t accidentally omit or misuse resource definitions.</p>"},{"location":"quotas-limits/#example-default-limits-and-requests","title":"Example: Default Limits and Requests","text":"<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: default-resources\nspec:\n  limits:\n  - default:\n      cpu: 500m\n      memory: 512Mi\n    defaultRequest:\n      cpu: 250m\n      memory: 256Mi\n    type: Container\n</code></pre> <p>This sets: - A default request and limit if none is provided in the Pod spec. - A guardrail to prevent containers from consuming too much by default.</p>"},{"location":"quotas-limits/#when-to-use-quotas-vs-limitranges","title":"When to Use Quotas vs LimitRanges","text":"Feature ResourceQuota LimitRange Scope Namespace-wide Per container Controls total usage \u2705 \u274c Sets defaults \u274c \u2705 Enforces boundaries \u2705 (hard enforcement) \u2705 (via defaults and min/max) Common Use Multi-team environments Developer guardrails"},{"location":"quotas-limits/#best-practices","title":"Best Practices","text":"<ul> <li>Use ResourceQuotas in shared clusters to prevent noisy neighbor problems.</li> <li>Apply LimitRanges to avoid under- or over-provisioned workloads.</li> <li>Combine both to enforce sane defaults and total caps.</li> <li>Monitor usage with <code>kubectl describe quota</code> or metrics dashboards.</li> <li>Document enforced limits for your teams to avoid confusion and failures.</li> </ul>"},{"location":"quotas-limits/#summary","title":"Summary","text":"<p>Kubernetes ResourceQuotas and LimitRanges are essential for managing shared cluster resources. They provide controls at both the namespace and container level, making it easier to ensure fairness, reduce waste, and maintain a healthy multi-tenant environment.</p>"},{"location":"rbac/","title":"RBAC (Role-Based Access Control)","text":"<p>RBAC controls who can do what in your Kubernetes cluster. It defines permissions to access the Kubernetes API, and is critical for securing multi-user environments.</p>"},{"location":"rbac/#core-concepts","title":"Core Concepts","text":"<p>Kubernetes RBAC works by granting verbs on resources to users or service accounts.</p>"},{"location":"rbac/#rbac-objects","title":"RBAC Objects","text":"Kind Purpose <code>Role</code> Grants permissions within a single namespace <code>ClusterRole</code> Grants permissions cluster-wide <code>RoleBinding</code> Assigns a Role to a user or group in a namespace <code>ClusterRoleBinding</code> Assigns a ClusterRole to a user or group across all namespaces"},{"location":"rbac/#example-read-only-role-in-a-namespace","title":"Example: Read-Only Role in a Namespace","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: pod-reader\n  namespace: dev\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"list\"]\n</code></pre>"},{"location":"rbac/#binding-the-role","title":"Binding the Role","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\n  namespace: dev\nsubjects:\n  - kind: User\n    name: alice\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>This lets <code>alice</code> read pods in the <code>dev</code> namespace only.</p>"},{"location":"rbac/#cluster-wide-example","title":"Cluster-Wide Example","text":"<p>To give a user full access to nodes and persistent volumes across the cluster:</p> <pre><code>kind: ClusterRole\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"nodes\", \"persistentvolumes\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Bind it using a <code>ClusterRoleBinding</code> to apply cluster-wide.</p>"},{"location":"rbac/#common-verbs","title":"Common Verbs","text":"<ul> <li><code>get</code>, <code>list</code>, <code>watch</code>: Read operations</li> <li><code>create</code>, <code>update</code>, <code>patch</code>, <code>delete</code>: Write operations</li> <li><code>impersonate</code>: Required to act as another user/service account</li> </ul>"},{"location":"rbac/#common-rbac-pitfalls","title":"Common RBAC Pitfalls","text":"<ul> <li>Forgetting to bind a Role: RBAC rules do nothing unless bound</li> <li>Using <code>ClusterRole</code> when <code>Role</code> is safer</li> <li>Not scoping permissions \u2014 always follow least privilege</li> </ul>"},{"location":"rbac/#audit-rbac","title":"Audit &amp; RBAC","text":"<p>Pair RBAC with audit logging to:</p> <ul> <li>Detect excessive privileges</li> <li>Track unauthorized access attempts</li> <li>Ensure least privilege policies are followed</li> </ul>"},{"location":"rbac/#summary","title":"Summary","text":"<ul> <li>RBAC defines access to Kubernetes API resources</li> <li>Use <code>Role</code>/<code>RoleBinding</code> for namespaced access, <code>ClusterRole</code> for global access</li> <li>Grant least privilege and bind only what\u2019s necessary</li> <li>Essential for securing clusters and enabling multi-team usage</li> </ul>"},{"location":"sec-context/","title":"Security Contexts","text":"<p>A Security Context defines privilege and access control settings for a Pod or container. It\u2019s how you harden workloads against privilege escalation, file system abuse, and host access.</p>"},{"location":"sec-context/#why-it-matters","title":"Why It Matters","text":"<p>By default, containers can:</p> <ul> <li>Run as root inside the container</li> <li>Access shared volumes with writable access</li> <li>Escalate privileges if not blocked</li> </ul> <p>Security contexts restrict and control this behavior \u2014 without needing to modify your image.</p>"},{"location":"sec-context/#pod-vs-container-security-contexts","title":"Pod vs Container Security Contexts","text":"<ul> <li>Pod-level applies to all containers in the Pod</li> <li>Container-level overrides the Pod-level settings</li> </ul>"},{"location":"sec-context/#common-fields","title":"Common Fields","text":"Field Purpose <code>runAsUser</code> Run as specific UID inside the container <code>runAsNonRoot</code> Force non-root user <code>readOnlyRootFilesystem</code> Prevent writing to root FS <code>allowPrivilegeEscalation</code> Block <code>setuid</code> or <code>sudo</code> actions <code>privileged</code> Gives access to host-level features (avoid) <code>capabilities</code> Add/drop Linux kernel capabilities"},{"location":"sec-context/#example-secure-container-context","title":"Example: Secure Container Context","text":"<pre><code>securityContext:\n  runAsNonRoot: true\n  runAsUser: 1000\n  readOnlyRootFilesystem: true\n  allowPrivilegeEscalation: false\n  capabilities:\n    drop: [\"ALL\"]\n</code></pre> <p>This setup:</p> <ul> <li>Ensures the container isn\u2019t running as root</li> <li>Forces read-only filesystem</li> <li>Blocks privilege escalation and kernel capabilities</li> </ul>"},{"location":"sec-context/#example-pod-level-context","title":"Example: Pod-Level Context","text":"<pre><code>spec:\n  securityContext:\n    fsGroup: 2000\n    runAsUser: 1000\n</code></pre> <ul> <li><code>fsGroup</code>: Sets file group ownership for mounted volumes</li> <li>Useful when containers need write access to shared volumes</li> </ul>"},{"location":"sec-context/#avoid-privileged-mode","title":"Avoid Privileged Mode","text":"<pre><code>securityContext:\n  privileged: true\n</code></pre> <p>This gives full host access \u2014 avoid unless you know exactly what you\u2019re doing (e.g., for a CNI plugin or host-level utility).</p>"},{"location":"sec-context/#quick-hardening-checklist","title":"Quick Hardening Checklist","text":"<ul> <li>\u2705 <code>runAsNonRoot: true</code></li> <li>\u2705 Drop all capabilities unless needed</li> <li>\u2705 Use <code>readOnlyRootFilesystem</code></li> <li>\u2705 Avoid <code>privileged: true</code></li> <li>\u2705 Explicitly set <code>runAsUser</code> and <code>fsGroup</code> for file access</li> </ul>"},{"location":"sec-context/#summary","title":"Summary","text":"<ul> <li>Security contexts define runtime privileges for Pods and containers</li> <li>Helps enforce least privilege and prevent lateral movement</li> <li>Combine with PodSecurity Admission and RBAC for layered defense</li> </ul>"},{"location":"security/","title":"Security Primer","text":"<p>Kubernetes security isn't just one feature \u2014 it's a collection of layered controls designed to protect clusters, workloads, data, and users. Understanding how these layers work together is critical to hardening your environment.</p>"},{"location":"security/#the-4cs-of-kubernetes-security","title":"The 4Cs of Kubernetes Security","text":"<p>Kubernetes security builds on the 4Cs model:</p> <ol> <li>Cloud / Infrastructure</li> <li>Cluster</li> <li>Container</li> <li>Code</li> </ol> <p>Each layer provides opportunities for both defense and attack. Strong security means securing each level, not just one.</p>"},{"location":"security/#common-threat-vectors","title":"Common Threat Vectors","text":"Surface Area Risk Example Misconfigured RBAC Users can access or delete sensitive resources Insecure Pods Privileged containers, exposed hostPath Unsafe Images Vulnerable base images or untrusted sources Over-permissive Network No NetworkPolicy = open lateral movement Secrets in plain text Poorly handled sensitive data"},{"location":"security/#key-kubernetes-security-concepts","title":"Key Kubernetes Security Concepts","text":"<p>Here\u2019s a quick overview of what you\u2019ll encounter in the upcoming sections:</p>"},{"location":"security/#authentication-authorization","title":"\ud83d\udd10 Authentication &amp; Authorization","text":"<ul> <li>Authentication \u2013 Who are you?</li> <li>Authorization (RBAC) \u2013 What can you do?</li> <li>Admission Controllers \u2013 Should this action be allowed or mutated?</li> </ul> <p>These mechanisms protect access to the Kubernetes API and workloads.</p>"},{"location":"security/#pod-security","title":"\ud83e\uddf1 Pod Security","text":"<ul> <li>Prevent privilege escalation</li> <li>Block host access</li> <li>Apply security contexts</li> <li>Enforce using Pod Security Admission (PSA)</li> </ul>"},{"location":"security/#audit-logs","title":"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f Audit Logs","text":"<ul> <li>Record every API request</li> <li>Help detect suspicious or unauthorized behavior</li> <li>Required for compliance in regulated environments</li> </ul>"},{"location":"security/#image-scanning","title":"\ud83d\udd0d Image Scanning","text":"<ul> <li>Analyze container images for known vulnerabilities</li> <li>Prevent deployment of unsafe workloads</li> <li>Tools: Trivy, Grype, Cosign, Clair</li> </ul>"},{"location":"security/#secrets-management","title":"\ud83d\udd10 Secrets Management","text":"<ul> <li>Use <code>Secret</code> objects (with encryption at rest)</li> <li>Avoid embedding secrets in images or environment variables</li> <li>Consider sealed secrets or external tools like Vault</li> </ul>"},{"location":"security/#network-security","title":"\ud83d\udd12 Network Security","text":"<ul> <li>Use NetworkPolicies to restrict Pod-to-Pod traffic</li> <li>Combine with Ingress controllers and TLS</li> <li>Isolate workloads by namespace or label</li> </ul>"},{"location":"security/#shift-left-devsecops-in-kubernetes","title":"Shift Left: DevSecOps in Kubernetes","text":"<p>Modern Kubernetes security integrates with CI/CD pipelines:</p> <ul> <li>Scan containers during build</li> <li>Validate policies (e.g., with OPA/Gatekeeper)</li> <li>Reject non-compliant resources before deployment</li> </ul>"},{"location":"security/#summary","title":"Summary","text":"<p>Kubernetes security is broad and layered. The upcoming sections break it down into actionable areas like:</p> <ul> <li>Pod-level hardening (PSA)</li> <li>Audit and observability</li> <li>Image security and scanning</li> <li>Runtime policies and network controls</li> </ul> <p>Security isn't a checkbox \u2014 it's a process. Let\u2019s dig into each piece.</p>"},{"location":"services-networking/","title":"Services &amp; Networking","text":"<p>Pods are ephemeral \u2014 they come and go. A Service gives you a stable way to communicate with groups of Pods, no matter how often those Pods restart, move, or scale.</p>"},{"location":"services-networking/#what-is-a-service","title":"What Is a Service?","text":"<p>A Kubernetes Service is an abstraction that:</p> <ul> <li>Selects a group of Pods using a label selector</li> <li>Assigns a stable IP and DNS name</li> <li>Forwards traffic to the correct Pods, even as they change</li> </ul> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: web\nspec:\n  selector:\n    app: web\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre> <p>This exposes Pods with label <code>app=web</code> on port 80, forwarding traffic to their port 8080.</p>"},{"location":"services-networking/#1-clusterip-default","title":"1. ClusterIP (default)","text":"<p>A ClusterIP Service exposes Pods within the cluster only.</p> <ul> <li>Internal IP address (<code>10.x.x.x</code>)</li> <li>DNS-resolvable: <code>web.default.svc.cluster.local</code></li> <li>Default Service type</li> </ul> <p> </p>"},{"location":"services-networking/#use-when","title":"Use When:","text":"<ul> <li>Services communicate internally (e.g., frontend \u2194 backend)</li> <li>You don\u2019t need external access</li> </ul>"},{"location":"services-networking/#2-nodeport","title":"2. NodePort","text":"<p>A NodePort Service exposes your app to the outside world using a static port on every node in the cluster.</p> <ul> <li>Uses the node's IP + assigned port (default range: <code>30000\u201332767</code>)</li> <li>Maps traffic from each node to the backing Pods</li> </ul> <pre><code>spec:\n  type: NodePort\n  ports:\n    - port: 80\n      targetPort: 8080\n      nodePort: 30080\n</code></pre> <p>Access from outside the cluster:</p> <pre><code>http://&lt;node-ip&gt;:30080\n</code></pre> <p> </p>"},{"location":"services-networking/#use-when_1","title":"Use When:","text":"<ul> <li>Testing external access without a LoadBalancer</li> <li>You don\u2019t have a cloud provider (e.g., on-prem clusters)</li> </ul>"},{"location":"services-networking/#3-loadbalancer","title":"3. LoadBalancer","text":"<p>A LoadBalancer Service provisions an external cloud load balancer (if supported by your environment).</p> <ul> <li>Only works with cloud providers (GCP, AWS, Azure)</li> <li>Assigns a public IP and balances across backing Pods</li> <li>Combines NodePort + external LB behind the scenes</li> </ul> <pre><code>spec:\n  type: LoadBalancer\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre> <p> </p>"},{"location":"services-networking/#use-when_2","title":"Use When:","text":"<ul> <li>You want public access to your app in a cloud environment</li> <li>You need external DNS + SSL termination (with Ingress)</li> </ul>"},{"location":"services-networking/#4-externalname-special-case","title":"4. ExternalName (Special Case)","text":"<p>Maps a Kubernetes Service to an external DNS name.</p> <pre><code>spec:\n  type: ExternalName\n  externalName: db.example.com\n</code></pre> <ul> <li>No selectors or backing Pods</li> <li>Useful for referencing external databases, APIs, etc.</li> </ul>"},{"location":"services-networking/#summary-table","title":"Summary Table","text":"Type Visibility Use Case Requires Cloud <code>ClusterIP</code> Internal only Pod-to-Pod communication No <code>NodePort</code> Exposes on node IP Direct external access via port No <code>LoadBalancer</code> External IP Cloud load balancer with public IP \u2705 Yes <code>ExternalName</code> DNS redirect External services via DNS No"},{"location":"services-networking/#summary","title":"Summary","text":"<ul> <li>Services abstract a group of Pods behind a stable IP and DNS name.</li> <li>ClusterIP is the default and internal-only.</li> <li>NodePort opens access via node IP and high port.</li> <li>LoadBalancer gives you a cloud-managed endpoint.</li> <li>ExternalName is a DNS-level alias.</li> </ul> <p>Understanding how each Service type works \u2014 and when to use it \u2014 is essential for building reliable, scalable apps in Kubernetes.</p>"},{"location":"statefulsets/","title":"StatefulSets","text":"<p>A StatefulSet is a Kubernetes controller for deploying and scaling stateful applications. Unlike Deployments, StatefulSets maintain persistent identity and storage for each Pod across rescheduling and restarts.</p>"},{"location":"statefulsets/#why-use-a-statefulset","title":"Why Use a StatefulSet?","text":"<p>Use a StatefulSet when your app requires:</p> <p>\u2705 Stable network identity (e.g., <code>pod-0</code>, <code>pod-1</code>) \u2705 Persistent storage per Pod that survives rescheduling \u2705 Ordered Pod startup, scaling, and deletion</p> <p>Examples: databases (PostgreSQL, Cassandra), Zookeeper, Kafka, etc.</p>"},{"location":"statefulsets/#how-it-differs-from-deployments","title":"How It Differs from Deployments","text":"<p>StatefulSets guarantee identity and storage, while Deployments prioritize replica management without caring about which Pod is which.</p> <p> </p> <p>Top Half (Deployment): Pod reschedule = new IP, broken volume mount Bottom Half (StatefulSet): Pod is recreated with the same IP, same volume</p>"},{"location":"statefulsets/#key-features","title":"Key Features","text":"Feature Deployment StatefulSet Pod name Random (e.g., <code>pod-abc123</code>) Stable (e.g., <code>web-0</code>, <code>web-1</code>) Pod start/delete order Any Ordered Persistent VolumeClaim Shared or ephemeral One per Pod DNS hostname Random Stable via headless service"},{"location":"statefulsets/#sample-yaml","title":"Sample YAML","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"web\"  # Headless service\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n          volumeMounts:\n            - name: data\n              mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n    - metadata:\n        name: data\n      spec:\n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 1Gi\n</code></pre>"},{"location":"statefulsets/#networking-dns","title":"Networking &amp; DNS","text":"<p>Pods in a StatefulSet get predictable hostnames:</p> <pre><code>web-0.web.default.svc.cluster.local\nweb-1.web.default.svc.cluster.local\n</code></pre> <p>This is enabled by the headless Service:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: web\nspec:\n  clusterIP: None  # Headless\n  selector:\n    app: web\n  ports:\n    - port: 80\n</code></pre>"},{"location":"statefulsets/#volume-behavior","title":"Volume Behavior","text":"<p>Each Pod gets its own PVC:</p> <ul> <li><code>web-0</code> \u2192 <code>data-web-0</code></li> <li><code>web-1</code> \u2192 <code>data-web-1</code></li> </ul> <p>These volumes are retained even if the Pod is deleted.</p>"},{"location":"statefulsets/#summary","title":"Summary","text":"<p>StatefulSets are essential when:</p> <ul> <li>Each Pod must retain identity, storage, and DNS</li> <li>Order of startup or shutdown matters</li> <li>Storage must be preserved between Pod rescheduling</li> </ul> <p>Use them wisely\u2014they\u2019re powerful but can be overkill for stateless services.</p>"},{"location":"storage/","title":"Storage in Kubernetes","text":"<p>Kubernetes provides flexible ways to persist data, from temporary in-Pod storage to persistent disks that survive Pod and node failure. You\u2019ll most commonly use Volumes, PersistentVolumes (PVs), and PersistentVolumeClaims (PVCs) to manage storage in production.</p>"},{"location":"storage/#types-of-storage","title":"Types of Storage","text":"<p>Kubernetes supports several storage mechanisms:</p> Type Description <code>emptyDir</code> Temporary, pod-level storage. Deleted when Pod is gone. <code>hostPath</code> Mounts a path on the host node. Avoid in production. <code>configMap</code> / <code>secret</code> Used for injecting configs/secrets into containers. <code>persistentVolume</code> Abstracts physical storage (EBS, NFS, GCE PD, etc.). <code>volumeClaimTemplate</code> Used by StatefulSets to dynamically provision volumes."},{"location":"storage/#volumes","title":"Volumes","text":"<p>Basic <code>volumes</code> are attached to a Pod spec and live as long as the Pod.</p> <pre><code>volumes:\n  - name: cache\n    emptyDir: {}\n</code></pre> <p>Use <code>emptyDir</code> for scratch space or caching \u2014 not persistent data.</p>"},{"location":"storage/#persistentvolumes-pvs-and-persistentvolumeclaims-pvcs","title":"PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs)","text":"<p>To persist data beyond the life of a Pod, use the PV + PVC model:</p> <ul> <li>A PV is a piece of actual storage (disk, NFS, etc.)</li> <li>A PVC is a user\u2019s request for storage</li> <li>Kubernetes binds them together dynamically</li> </ul>"},{"location":"storage/#pvc-example","title":"PVC Example","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-storage\nspec:\n  accessModes: [\"ReadWriteOnce\"]\n  resources:\n    requests:\n      storage: 1Gi\n</code></pre>"},{"location":"storage/#pod-using-the-pvc","title":"Pod using the PVC","text":"<pre><code>volumes:\n  - name: app-data\n    persistentVolumeClaim:\n      claimName: app-storage\n\ncontainers:\n  - name: web\n    volumeMounts:\n      - name: app-data\n        mountPath: /data\n</code></pre>"},{"location":"storage/#volume-modes-access","title":"Volume Modes &amp; Access","text":"<ul> <li>Volume Modes:</li> <li><code>Filesystem</code> (default): mounts as a directory</li> <li> <p><code>Block</code>: exposes the raw device</p> </li> <li> <p>Access Modes:</p> </li> <li><code>ReadWriteOnce</code>: one node read/write</li> <li><code>ReadOnlyMany</code>: multiple nodes read-only</li> <li><code>ReadWriteMany</code>: shared read/write (NFS, etc.)</li> </ul>"},{"location":"storage/#storageclasses","title":"StorageClasses","text":"<p>A <code>StorageClass</code> defines how storage should be provisioned dynamically.</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast\nprovisioner: kubernetes.io/gce-pd\nparameters:\n  type: pd-ssd\n</code></pre> <p>The cluster admin defines StorageClasses; PVCs can request one by name.</p> <pre><code>storageClassName: fast\n</code></pre>"},{"location":"storage/#dynamic-vs-static-provisioning","title":"Dynamic vs Static Provisioning","text":"<ul> <li>Dynamic: PVC automatically provisions a volume using a <code>StorageClass</code>.</li> <li>Static: Admin manually creates PVs, and users bind to them with matching PVCs.</li> </ul>"},{"location":"storage/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>ReadWriteOnce</code> unless your workload requires multi-node access.</li> <li>Leverage <code>StorageClass</code> for automated provisioning.</li> <li>Clean up PVCs when no longer needed \u2014 they may retain bound disks.</li> <li>Use StatefulSets if each Pod needs its own PVC.</li> </ul>"},{"location":"storage/#summary","title":"Summary","text":"<p>Storage in Kubernetes is abstracted through PVs and PVCs for flexibility and portability. Whether your app is stateless or stateful, Kubernetes can handle your storage needs \u2014 just make sure to pick the right type of volume for the job.</p>"},{"location":"troubleshooting/","title":"Troubleshooting Kubernetes","text":"<p>Troubleshooting is a crucial skill for managing Kubernetes clusters. This section provides strategies and tools for diagnosing and resolving common issues.</p>"},{"location":"troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"Issue Description Solution CrashLoopBackOff Pod repeatedly crashing. Check logs with <code>kubectl logs &lt;pod-name&gt;</code>. ImagePullBackOff Kubernetes cannot pull the container image. Verify the image name and credentials. Node Not Ready Node is not functioning correctly. Check node status with <code>kubectl get nodes</code> and review the kubelet logs. Disk Pressure Node runs low on disk space. Free up space or add more storage. Service Not Accessible Service configuration or endpoints issue. Check service configuration with <code>kubectl get svc</code> and <code>kubectl describe svc &lt;service-name&gt;</code>. DNS Resolution Failures DNS pod status or configuration issue. Verify DNS pod status and configuration with <code>kubectl get pods -n kube-system</code>. Pod Eviction Pods are evicted due to resource constraints. Check node resource usage and adjust limits or requests. High CPU Usage Pods or nodes experiencing high CPU usage. Analyze CPU usage with <code>kubectl top</code> and optimize application resource requests. Network Latency High latency in network communication between Pods. Check network policies and configurations, and ensure sufficient bandwidth."},{"location":"troubleshooting/#tools-for-troubleshooting","title":"Tools for Troubleshooting","text":"Command Description Example Usage <code>describe</code> Provides detailed information about resources. <code>kubectl describe pod &lt;pod-name&gt;</code> <code>logs</code> Retrieves logs from containers. <code>kubectl logs &lt;pod-name&gt;</code> <code>exec</code> Executes commands in a container. <code>kubectl exec -it &lt;pod-name&gt; -- /bin/sh</code> Monitoring and Logging <ul> <li>Prometheus: Collects metrics and provides alerts. It's highly customizable and integrates well with Kubernetes. Learn more</li> <li>Grafana: Visualizes metrics collected by Prometheus and other sources. It offers a rich set of dashboards and visualization tools. Learn more</li> <li>Elasticsearch, Fluentd, Kibana (EFK) Stack: Centralizes logging and provides search capabilities. Elasticsearch stores logs, Fluentd collects and forwards them, and Kibana visualizes the data. Learn more about Elasticsearch, Fluentd, Kibana</li> </ul>"},{"location":"troubleshooting/#best-practices","title":"Best Practices","text":"<ul> <li>Regular Monitoring: Continuously monitor cluster health and performance.</li> <li>Automated Alerts: Set up alerts for critical issues to ensure timely response.</li> <li>Documentation: Keep detailed records of issues and solutions for future reference.</li> </ul>"}]}